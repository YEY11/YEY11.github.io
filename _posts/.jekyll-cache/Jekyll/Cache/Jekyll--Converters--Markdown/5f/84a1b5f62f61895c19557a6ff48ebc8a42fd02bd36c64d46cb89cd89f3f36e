I"<!-- 数学公式 -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
  });
</script>

<h1 id="lecture-18-高斯混合模型和-em-算法">Lecture 18 高斯混合模型和 EM 算法</h1>
<h2 id="主要内容">主要内容</h2>
<ul>
  <li><strong>无监督学习</strong>
    <ul>
      <li>问题的多样性</li>
    </ul>
  </li>
  <li><strong>高斯混合模型（GMM）</strong>
    <ul>
      <li>一种用于聚类的概率方法</li>
      <li>GMM</li>
      <li>优化问题的 GMM 聚类</li>
    </ul>
  </li>
  <li><strong>期望最大化（EM）算法</strong>
    <h2 id="1-无监督学习">1. 无监督学习</h2>
    <p><strong>机器学习中的一个大的分支，关注在标签缺失的数据上学习其结构</strong></p>
    <h3 id="11-在此之前监督学习">1.1 在此之前：监督学习</h3>
  </li>
  <li>监督学习：总体目标是根据数据做出预测</li>
  <li>为此，我们学习了诸如：随机森林、ANN 和 SVM 等算法</li>
  <li>我们有实例 $\boldsymbol x_i\in \boldsymbol R^m\;(i=1,…,n)$，以及对应的标签 $y_i$ 作为输入，目标是预测新的实例的标签。</li>
</ul>

<h2 id="总结">总结</h2>

<p>下节内容：高斯混合模型（GMM）和期望最大化（EM）</p>
:ET