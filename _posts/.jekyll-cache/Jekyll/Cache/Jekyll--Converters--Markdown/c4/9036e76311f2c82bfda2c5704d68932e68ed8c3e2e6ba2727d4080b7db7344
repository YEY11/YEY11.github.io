I"<!-- 数学公式 -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
  });
</script>

<h1 id="lecture-19-降维">Lecture 19 降维</h1>
<h2 id="主要内容">主要内容</h2>
<ul>
  <li><strong>主成成分分析（PCA）</strong>
    <ul>
      <li>线性降维方法</li>
      <li>对角化协方差矩阵</li>
    </ul>
  </li>
  <li><strong>核化 PCA</strong></li>
</ul>

<h2 id="1-关于降维">1. 关于降维</h2>
<h3 id="11-数据的真实维度">1.1 数据的真实维度？</h3>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-27-WX20200227-151842%402x.png" width="80%" /></p>

<h3 id="12-降维">1.2 降维</h3>
<ul>
  <li>之前我们介绍了无监督学习中的一类常见任务：聚类</li>
  <li><strong>降维</strong> 是指使用 <span style="color:red">较少数量的变量</span>（维度）来表示数据，同时保留数据中我们 <span style="color:red">“感兴趣的”</span> 结构</li>
  <li>通过降维，我们可以达到以下目的：
    <ul>
      <li><span style="color:red">可视化</span>（例如，将高维数据映射到 2D）</li>
      <li>提高 pipeline 中的 <span style="color:red">计算效率</span></li>
      <li>提升 pipeline 中的数据压缩或者 <span style="color:red">统计效率</span></li>
    </ul>
  </li>
</ul>

<h3 id="13-探索数据结构">1.3 探索数据结构</h3>
<ul>
  <li>一般而言，降维会导致信息丢失</li>
  <li>诀窍是确保大部分我们 “感兴趣的” 信息被保留下来，而丢失的大部分都属于噪声</li>
  <li>这通常是可能的，因为相比那些记录的变量，真实数据具有的 <span style="color:red">内在维度可能要少得多</span></li>
  <li><strong>例子：</strong> GPS 坐标是 3D 的，而平坦道路上的汽车定位实际是在 2D 流形上的</li>
</ul>

<h2 id="2-主成成分分析pca">2. 主成成分分析（PCA）</h2>
<p><strong>寻找一种数据的旋转方式使得（新）变量之间的协方差最小化</strong></p>

<h3 id="21-主成成分分析">2.1 主成成分分析</h3>
<ul>
  <li>主成成分分析（PCA）是普遍用于降维和数据分析的一种常用方法</li>
  <li>给定一个数据集 $\boldsymbol x_1,…,\boldsymbol x_n$，其中 $\boldsymbol x_i\in \boldsymbol R^m$，PCA 的目标是找到一个新的坐标系，使得大部分方差都集中在第一个坐标轴上，然后剩下的大部分方差都集中在第二个坐标轴上，以此类推</li>
  <li>然后，降维是基于 <span style="color:red">丢弃坐标</span> 实现的，我们仅保留前 $l$ 个坐标，丢弃后面的其余坐标（$l&lt; m$）</li>
</ul>

<h2 id="总结">总结</h2>
<ul>
  <li>无监督学习
    <ul>
      <li>问题的多样性</li>
    </ul>
  </li>
  <li>高斯混合模型（GMM）
    <ul>
      <li>一种聚类的概率方法</li>
      <li>GMM 模型</li>
      <li>GMM 聚类作为一个优化问题</li>
    </ul>
  </li>
  <li>期望最大化（EM）算法</li>
</ul>

<p>下节内容：降维</p>
:ET