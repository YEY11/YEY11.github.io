I"4<!-- 数学公式 -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
  });
</script>

<h1 id="lecture-16-概率图模型">Lecture 16 概率图模型</h1>
<h2 id="主要内容">主要内容</h2>
<ul>
  <li><strong>联合分布的表示</strong></li>
  <li><strong>条件 / 边缘独立</strong>
    <ul>
      <li>有向 vs 无向</li>
    </ul>
  </li>
</ul>

<h2 id="1-概率图模型">1. 概率图模型</h2>
<p><strong>图论与概率论的结合，贝叶斯统计学习的首选工具。我们将从简单的离散情况出发，再延伸到连续情况。</strong></p>
<h3 id="11-实际意义驱动">1.1 实际意义驱动</h3>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-22-WX20200222-135207%402x.png" width="50%" /></p>

<p><strong><span style="color:steelblue">很多应用</span></strong></p>
<ul>
  <li>进化树</li>
  <li>谱分析、关联分析</li>
  <li>错误控制代码</li>
  <li>语音识别</li>
  <li>文档主题模型</li>
  <li>概率解析</li>
  <li>图像分割</li>
  <li>…</li>
</ul>

<p><strong><span style="color:steelblue">发现的算法</span></strong></p>
<ul>
  <li>HMM</li>
  <li>卡尔曼滤波器</li>
  <li>混合模型</li>
  <li>LDA</li>
  <li>MRF</li>
  <li>CRF</li>
  <li>Logistic 回归、线性回归</li>
  <li>…</li>
</ul>

<h3 id="12-比较方式驱动">1.2 比较方式驱动</h3>
<p><strong><span style="color:steelblue">贝叶斯统计学习</span></strong></p>
<ul>
  <li>对 $\boldsymbol X, \boldsymbol y$ 和参数随机变量的联合分布进行建模
    <ul>
      <li>“先验”：参数边缘化</li>
    </ul>
  </li>
  <li>训练：利用观测数据，将先验更新为后验</li>
  <li>预测：输出后验，或者后验的某个函数（MAP）</li>
</ul>

<p><strong><span style="color:steelblue">概率图模型（PGM），又称 “贝叶斯网络”</span></strong></p>
<ul>
  <li>高效的联合表示
    <ul>
      <li>显式表示独立性</li>
      <li>容易在表达性和数据需求之间做出权衡</li>
      <li>易于从业者建模</li>
      <li>拟合参数、计算边缘和后验的算法</li>
    </ul>
  </li>
</ul>

<h3 id="13-一切始于联合分布">1.3 一切始于联合分布</h3>
<ul>
  <li>所有离散随机变量的联合分布都可以用表格表示</li>
  <li>随着随机变量数量的增加，表格行数呈指数上升</li>
  <li>例子：真值表
    <ul>
      <li>$m$ 个布尔随机变量需要 $(2^m-1)$ 行</li>
      <li>表格为每行分配概率</li>
    </ul>

    <p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-22-WX20200222-144337%402x.png" width="80%" /></p>
  </li>
</ul>

<h3 id="14-好处我们可以基于联合分布做些什么">1.4 好处：我们可以基于联合分布做些什么？</h3>
<ul>
  <li>根据随机变量的联合分布进行 <strong>概率推断</strong>
    <ul>
      <li>计算任何涉及这些随机变量的其他分布</li>
    </ul>
  </li>
  <li>模式：已有联合分布，希望得到一个分布<br />
利用：<span style="color:steelblue">贝叶斯规则</span> + <span style="color:red">边缘化</span></li>
  <li><strong>例子：朴素贝叶斯分类器</strong>
    <ul>
      <li>预测实例 $\boldsymbol x$ 的类别 $y$，通过最大化</li>
    </ul>

    <script type="math/tex; mode=display">\Pr(Y=y|\boldsymbol X=\boldsymbol x)=\dfrac{\color{steelblue}{\Pr(Y=y,\boldsymbol X=\boldsymbol x)}}{\color{steelblue}{\Pr(\boldsymbol X=\boldsymbol x)}}=\dfrac{\Pr(Y=y,\boldsymbol X=\boldsymbol x)}{\color{red}{\sum_y \Pr(\boldsymbol X=\boldsymbol x,Y=y)}}</script>

    <p>回忆：连续分布（在参数上）的积分与离散分布的求和等价（均称为边缘化）</p>
  </li>
</ul>

<h3 id="15-坏处和丑陋表格会变得非常大">1.5 坏处和丑陋：表格会变得非常大</h3>
<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-22-WX20200222-161819%402x.png" width="30%" align="right" /></p>

<ul>
  <li><strong>坏处：</strong> 计算复杂度
    <ul>
      <li>表格行数随着随机变量的增加呈指数增长</li>
      <li>因此 $\to$ 边缘化的空间和时间不足</li>
    </ul>
  </li>
  <li><strong>丑陋：</strong> 模型复杂度
    <ul>
      <li>太过灵活</li>
      <li>太多参数需要拟合<br />
$\to$ 需要大量数据，否则会过拟合</li>
    </ul>
  </li>
  <li>对抗手段：假设独立<br />
<br /></li>
</ul>

<h3 id="16-例子你迟到了">1.6 例子：你迟到了</h3>
<ul>
  <li>对一个喜欢迟到的老师进行建模，使用布尔随机变量
    <ul>
      <li>$\color{red}{T}$：班级教学老师是 Ben</li>
      <li>$\color{steelblue}{S}$：大晴天（否则为坏天气）</li>
      <li>$\color{purple}{L}$：老师迟到了（否则为准时到达）</li>
    </ul>
  </li>
  <li>假设：Ben 有时会因为坏天气而迟到，Ben 比其他教师更容易迟到
    <ul>
      <li>
        <p>$\Pr(\color{steelblue}{S}|\color{red}{T})=\Pr(\color{steelblue}{S})$</p>

        <p>$\Pr(\color{steelblue}{S})=0.3$</p>

        <p>$\Pr(\color{red}{T})=0.6$</p>
      </li>
    </ul>
  </li>
  <li>迟到不独立于天气和老师
    <ul>
      <li>需要考虑 $\Pr(\color{purple}{L}| \color{red}{T=t},\color{steelblue}{S=s})$ 的所有组合<br />
<img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-22-WX20200222-163733%402x.png" width="50%" /></li>
    </ul>
  </li>
  <li>只需要 6 个参数</li>
</ul>

<h3 id="17-独立性">1.7 独立性</h3>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-22-WX20200222-164111%402x.png" /></p>

<ul>
  <li>独立性假设
    <ul>
      <li>随机变量之间是否满足独立性，可以根据领域专业知识做出合理判断</li>
      <li>允许我们通过直接因式分解来计算联合概率 $\to$ 模型易处理的关键</li>
    </ul>
  </li>
</ul>

<h3 id="18-联合分布因式分解">1.8 联合分布因式分解</h3>
<ul>
  <li>
    <p><span style="color:red">链式法则：</span> 对于任意顺序的随机变量总是可以因式分解为</p>

    <script type="math/tex; mode=display">\Pr(X_1,X_2,...,X_k)=\prod_{i=1}^{k}\Pr(X_i|X_{i+1},...,X_k)</script>
  </li>
  <li>模型的独立性假设对应于
    <ul>
      <li>消除因子中的条件随机变量</li>
      <li><span style="color:red">无条件独立</span> 的例子：$\Pr(X_1|X_2)=\Pr(X_1)$</li>
      <li>
        <table>
          <tbody>
            <tr>
              <td><span style="color:red">条件独立</span> 的例子：$\Pr(X_1|X_2,X_3)=\Pr(X_1</td>
              <td>X_2)$</td>
            </tr>
          </tbody>
        </table>
      </li>
    </ul>
  </li>
  <li>例子：独立随机变量 $\Pr(X_1,…,X_k)=\prod_{i=1}^{k}\Pr(X_i)$</li>
  <li>更简单的因式分解可以：<span style="color:red">加速推断过程</span>，以及 <span style="color:red">防止过拟合</span></li>
</ul>

<h3 id="19-有向-pgm">1.9 有向 PGM</h3>
<ul>
  <li><span style="color:red">节点</span> 表示 <span style="color:red">随机变量</span></li>
  <li><span style="color:red">边</span>（无环的）表示 <span style="color:red">条件独立</span>
    <ul>
      <li><span style="color:red">节点表：</span> $\Pr(child \mid parents)$</li>
      <li>子节点（$child$）直接取决于 父母节点（$parents$）</li>
    </ul>
  </li>
  <li>
    <p><span style="color:red">联合因式分解</span></p>

    <script type="math/tex; mode=display">\Pr(X_1,X_2,...,X_k)=\prod_{i=1}^{k}\Pr(X_i|X_j \in parents(X_i))</script>
  </li>
</ul>

<p><strong><span style="color:steelblue">迟到教师的例子</span></strong></p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-22-WX20200222-171406%402x.png" width="80%" /></p>

<h3 id="110-例子核电站">1.10 例子：核电站</h3>
<ul>
  <li>核心温度 $\to$ 温度表 $\to$ 警报</li>
  <li>监控故障中的模型不确定性
    <ul>
      <li>GRL：gauge reads low（温度表显示低数值）</li>
      <li>CTL: core temperature low（核心温度低）</li>
      <li>FG: faulty gauge（温度表故障）</li>
      <li>FA: faulty alarm（警报故障）</li>
      <li>AS: alarm sounds（警报响起）</li>
    </ul>
  </li>
  <li>
    <p>PGM 解决问题</p>

    <p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-22-WX20200222-173144%402x.png" width="50%" /></p>

    <p>联合概率 $\Pr(CTL,FG,FA,GRL,AS)$ 由下式给出：</p>

    <script type="math/tex; mode=display">\Pr(AS|FA,GRL)\, \Pr(FA)\, \Pr(GRL|CTL,FG)\, \Pr(CTL)\, \Pr(FG)</script>
  </li>
</ul>

<h3 id="111-朴素贝叶斯">1.11 朴素贝叶斯</h3>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-22-WX20200222-173838%402x-1.png" width="65%" /></p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\Pr(Y,X_1,...,X_d) &= \Pr(X_d,...,X_1,Y) \\
&= \Pr(X_1|Y)\,\Pr(X_2|X_1,Y)\, ...\, \Pr(X_d|X_1,...,X_{d-1},Y)\, \Pr(Y) \\
&= \Pr(X_1|Y)\, \Pr(X_2|Y)\, ... \, \Pr(X_d|Y)\, \Pr(Y)
\end{align} %]]></script>

<p>预测：基于最大化 $\Pr(Y|X_1,…,X_d)$ 预测标签</p>

<p><strong><a href="https://www.cnblogs.com/wintergrass/archive/2011/11/14/2248317.html">重复的简记：盘子表示（Plate notation）</a></strong></p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-22-WX20200222-175513%402x.png" width="60%" /></p>

<h3 id="112-pgm-频率学家或者贝叶斯人">1.12 PGM 频率学家或者贝叶斯人</h3>
<ul>
  <li>PGM 表示联合概率，这是贝叶斯学派的中心</li>
  <li>
    <p>贝叶斯在此基础上：<span style="color:red">为每个参数添加节点</span>，以及参数先验的表格<br /></p>

    <p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-22-WX20200222-180146%402x.png" width="65%" /></p>
  </li>
</ul>

<h2 id="2-无向-pgm">2. 无向 PGM</h2>
<p><strong>PGM 的无向变体，通过变量的任意正值函数进行参数化，并进行全局归一化。又称为 “马尔可夫随机场”。</strong></p>
<h3 id="21-无向-vs-有向">2.1 无向 vs 有向</h3>
<p><strong><span style="color:red">无向 PGM</span></strong></p>
<ul>
  <li>图
    <ul>
      <li>边是无向的</li>
    </ul>
  </li>
  <li>概率
    <ul>
      <li>每个节点都是一个随机变量</li>
      <li>每个 clique $C$ 都有 “factor”：$\psi_C(X_j:j\in C)\ge 0$</li>
      <li>联合概率 $\propto$ factor 的乘积</li>
    </ul>
  </li>
</ul>

<p><strong><span style="color:red">有向 PGM</span></strong></p>
<ul>
  <li>图
    <ul>
      <li>边是有向的</li>
    </ul>
  </li>
  <li>概率
    <ul>
      <li>每个节点都是一个随机变量</li>
      <li>
        <table>
          <tbody>
            <tr>
              <td>每个节点都有条件概率：$\Pr\left(X_i</td>
              <td>X_j \in parents(X_i)\right)$</td>
            </tr>
          </tbody>
        </table>
      </li>
      <li>联合概率 $=$ 条件概率的乘积</li>
    </ul>
  </li>
</ul>

<p><strong><span style="color:red">关键区别：归一化</span></strong></p>

<h3 id="22-无向-pgm-公式">2.2 无向 PGM 公式</h3>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-02-22-WX20200222-191201%402x.png" width="40%" align="right" /></p>

<ul>
  <li><strong><span style="color:orange">Clique：</span></strong> 一个 <strong>全连接</strong> 节点的集合
    <ul>
      <li>全连接的意思是集合中的各点之间两两相连，例如：A-D, C-D, C-D-F。</li>
    </ul>
  </li>
  <li><strong><span style="color:orange">Maximal clique：</span></strong> 图中 <strong>最大的</strong> cliques
    <ul>
      <li>注意：这里最大 cliques <strong>不是指节点数量最多，而是说不能再加入新的节点了</strong>，所以， C-D 不是, 因为还有 C-D-F。</li>
      <li>此外，D-E 也是，因为再往这个集合之中添加任何节点，都不能满足各节点两两相连从而构成一个 clique 了。</li>
    </ul>
  </li>
  <li>
    <p>联合概率由下式定义</p>

    <script type="math/tex; mode=display">\Pr(a,b,c,d,e,f)=\dfrac{1}{Z}\psi_1(a,b)\,\psi_2(b,c)\,\psi_3(a,d)\,\psi_4(d,c,f)\,\psi_5(d,e)</script>

    <ul>
      <li>
        <p>其中，$\psi$ 是一个正值函数，$Z$ 是归一化 “分区” 函数</p>

        <script type="math/tex; mode=display">Z=\sum \limits_{a,b,c,d,e,f}\psi_1(a,b)\,\psi_2(b,c)\,\psi_3(a,d)\,\psi_4(d,c,f)\,\psi_5(d,e)</script>
      </li>
    </ul>
  </li>
</ul>

<h3 id="23-有向到无向">2.3 有向到无向</h3>
<ul>
  <li>
    <p>有向 PGM 公式为</p>

    <script type="math/tex; mode=display">P(X_1,X_2,...,X_k)=\prod_{i=1}^{k}\Pr(X_i|X_{\pi_i})</script>

    <p>其中，$\boldsymbol \pi$ 是父母节点的索引。</p>
  </li>
  <li>
    <p>等价于无向 PGM，其中</p>
    <ul>
      <li></li>
    </ul>
  </li>
</ul>

<h2 id="总结">总结</h2>
<ul>
  <li>离散设定下的贝叶斯思想
    <ul>
      <li>Beta-Binomial 共轭</li>
    </ul>
  </li>
  <li>贝叶斯分类
    <ul>
      <li>非共轭的渐进必要性</li>
    </ul>
  </li>
</ul>

<p>下节内容：概率图模型</p>
:ET