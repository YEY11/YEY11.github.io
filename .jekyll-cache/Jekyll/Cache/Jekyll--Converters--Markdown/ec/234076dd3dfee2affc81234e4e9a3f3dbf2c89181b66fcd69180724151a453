I"?<h1 id="lecture-07-非线性模型">Lecture 07 非线性模型</h1>

<p><strong>参考教材</strong>：</p>

<ul>
  <li><em>Gareth, J., Daniela, W., Trevor, H., &amp; Robert, T. (2013). An intruduction to statistical learning: with applications in R. Spinger.</em></li>
  <li><em>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). The elements of statistical learning: data mining, inference, and prediction. Spinger Science &amp; Business Media.</em></li>
</ul>

<h2 id="1-引言">1. 引言</h2>

<p>目前为止，我们讨论的内容大多集中于线性模型。相比于其他模型而言，线性模型更易于描述、实现简单、解释性和推断理论都相对成熟。然而，我们也不能回避标准线性回归模型在预测上明显不足的问题。这是因为模型的线性假设通常只是对真实函数的一种近似，有时这种近似效果并不理想。</p>

<p>上节课中，我们介绍了一些用于提升线性回归模型预测效果的模型，例如：基于最小二乘的岭回归、Lasso、PCR 和 PLS。这些模型在降低线性模型复杂度的同时也降低了估计的方差。但事实上，线性模型的形式仍未改变。</p>

<p>本节课中，我们将介绍一些非线性模型，它们在保证良好的可解释性的前提下，通过放松线性假设对原始线性模进行简单推广，例如：</p>

<ul>
  <li>
    <p><strong>多项式回归 (Polynomial regression)</strong>：用原始预测变量的幂作为新的预测变量以替代原始变量。例如：一个三次回归模型包含三个预测变量 $X,X^2,X^3$。这是一种简单实用的表达数据非线性关系的模型。</p>

    <p><br /></p>
  </li>
  <li>
    <p><strong>阶梯函数 (Step functions)</strong>：将某个预测变量的取值空间分割成 $K$ 个不同区域，以此来生成一个新的定性变量，分段拟合一个常量函数。</p>

    <p><br /></p>
  </li>
  <li>
    <p><strong>回归样条 (Regression spline)</strong>：该方法在形式上比多项式回归和阶梯拟合方法更灵活，实际上回归样条可以视为前两类方法的推广。首先将 $X$ 的取值范围分割成 $K$ 个区域，在每个区域上分别独立拟合一个多项式函数。然而，通常会对这些多项式函数进行一些限制以保证在区域边界或 <strong>结点 (knots)</strong> 处的连接是光滑的。只要将 $X$ 的取值区间划分为足够多的区域，此方法就能够产生灵活度很高的拟合。</p>

    <p><br /></p>
  </li>
  <li>
    <p><strong>光滑样条 (Smoothing splines)</strong>：与回归样条类似，但是产生机制略有不同，一般是通过最小化一个带光滑惩罚项的残差平方和的式子来得到光滑样条的结果。</p>

    <p><br /></p>
  </li>
  <li>
    <p><strong>局部回归 (Local regression)</strong>：与样条方法类似，但是存在一个重大差别：局部回归中的区域之间是允许重叠的，并且这种重叠将以一种非常光滑的方式完成。</p>

    <p><br /></p>
  </li>
  <li>
    <p><strong>广义可加模型 (Generalized additive models)</strong>：实际上是将上述模型推广到多个预测变量的情况。</p>
  </li>
</ul>

<p>上述方法都具有很高的灵活性，并且不会丢失线性模型的简单性和可解释性。</p>

<h2 id="2-多项式回归">2. 多项式回归</h2>

<p>为了体现响应变量和预测变量之间的非线性关系，将线性模型推广的最自然的方法是将标准线性模型替换为一个多项式函数：</p>

<script type="math/tex; mode=display">y_i = \beta_0 + \beta_1 x_i + \beta_2 x_i^2 + \beta_3 x_i^3 + \dots + \beta_d x_i^d + \epsilon_i</script>

<p>其中，$\epsilon_i$ 是误差项。这种方法称为 <strong>多项式回归</strong>。对于阶数比较大的 $d$，多项式回归将呈现明显的非线性曲线。</p>

<p>注意到其本质上可视为预测变量 $x_i,x_i^2,x_i^3,\dots,x_i^d$ 的标准线性模型，因此用最小二乘回归的方法就能得到其系数的估计。对多项式阶数 $d$ 的选择不宜过大，一般不大于 $3$ 或者 $4$，这是因为 $d$ 越大，多项式曲线就会变得过于灵活，以至于出现一些奇怪的形状，尤其是在 $X$ 变量的边界附近。</p>

<p>图 1 的左图是 <code class="language-plaintext highlighter-rouge">Wage</code> 数据集中的 <code class="language-plaintext highlighter-rouge">wage</code> 变量关于 <code class="language-plaintext highlighter-rouge">age</code> 变量的散点图，其中包含了居住在美国亚特兰大中部地区男性的收入和人口信息。图中蓝色实线是使用最小二乘法拟合的 $4$ 阶多项式回归的结果。尽管表面上看，这个模型与其他线性回归模型并无明显差异，但每个变量的系数不再是模型关注的重点。相反，通过观察 <code class="language-plaintext highlighter-rouge">age</code> 在 $18$ 岁到 $80$ 岁之间的 $62$ 个观测值的函数拟合结果，可以帮助我们更好地理解 <code class="language-plaintext highlighter-rouge">age</code> 和 <code class="language-plaintext highlighter-rouge">wage</code> 的关系。</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-11-09-WX20201110-003200%402x.png" width="80%" /></p>

<p><span style="margin:auto; display:table; font-size:10pt"> <span style="color:steelblue;font-weight:bold">图 1</span>：<code class="language-plaintext highlighter-rouge">Wage</code> 数据集。<strong>左图</strong>：实线表示 <code class="language-plaintext highlighter-rouge">wage</code> (单位：千美元) 关于 <code class="language-plaintext highlighter-rouge">age</code> 的 $4$ 阶多项式模型曲线，用最小二乘法拟合；虚线表示 $95\%$ 置信区间。<strong>右图</strong>：针对二元变量 <code class="language-plaintext highlighter-rouge">wage &gt;250</code> 的逻辑回归模型建模结果，通常采用 $4$ 阶多项式，蓝色实线表示 <code class="language-plaintext highlighter-rouge">wage &gt;250</code> 的后验概率，虚线则是估计的 $95\%$ 置信区间。</span></p>

<p>首先创建一些新的变量 $X_1=X, X_2=X^2,\dots$，然后按照多元线性回归的方式拟合它们。</p>

<p>这里，我们真正关心的并非回归系数，而是在任意一个 $x_0$ 处的拟合函数值：</p>

<script type="math/tex; mode=display">\hat f(x_0) = \hat \beta_0 + \hat \beta_1 x_0+ \hat \beta_2 x_0^2+ \hat \beta_3 x_0^3+ \hat \beta_4 x_0^4</script>

<p>由于 $\hat f(x_0)$ 是一个关于 $\hat \beta_{\ell}$ 的线性函数，我们可以得到一个在任意 $x_0$ 处的 <strong>点方差 (pointwise-variances)</strong> $\mathrm{Var}[\hat f(x_0)]$ 的简单表示。在图 1 中，我们已经计算了 $x_0$ 值组成的网格上的拟合值和 <strong>点标准误 (pointwise standard errors)</strong>。并且画出了出拟合值曲线以及距离拟合值两倍标准误的曲线，即 $\hat f(x_0) \pm 2 \cdot \mathrm{se}[\hat f(x_0)]$。之所以取两倍标准误是因为为对于正态分布的误差项来说，这个值对应的大约是 $95\%$ 置信区间。</p>

<p>通常，我们要么将阶数 $d$ 固定在一个合理的较低值，要么使用交叉验证来选择 $d$。</p>

<p>从图 1 可以看出，工资好像是来自于两个不同的总体：一个总体是年收入高于 $250$ 千美元的高收入组，而另一个则是低收入组。将 <code class="language-plaintext highlighter-rouge">wage</code> 看作一个二元变量就能将数据分成两个组。这样以 <code class="language-plaintext highlighter-rouge">age</code> 的多项式函数作为预测变量的逻辑回归就能用来预测这个二元响应变量。换句话说，实际上需要拟合的是下面这个模型：</p>

<script type="math/tex; mode=display">\Pr(y_i > 250 \mid x_i) = \dfrac{\exp(\beta_0 + \beta_1 x_i + \beta_2 x_i^2 +  \dots + \beta_d x_i^d)}{1 + \exp(\beta_0 + \beta_1 x_i + \beta_2 x_i^2 + \dots + \beta_d x_i^d)}</script>

<p>为了获得其置信区间，只需要计算相关的 $\mathrm{logit}$ 函数的上下限，然后取反即可得到概率的置信区间。</p>

<p>并且，我们可以将多个变量分开处理，只需将变量堆叠到一个矩阵中，然后将进行分区计算即可 (参见后面的 GAM)。</p>

<p><strong>注意</strong>：多项式函数具有臭名昭著的 <strong>尾部行为 (tail behavior)</strong>，这会导致推断非常困难。</p>

<p>在 R 中，我们可以在 <code class="language-plaintext highlighter-rouge">formula</code> 参数中使用 <code class="language-plaintext highlighter-rouge">y ~ poly(x, degree=3)</code> 进行多项式拟合。</p>

<h2 id="3-阶梯函数">3. 阶梯函数</h2>

<p>在线性模型中使用特征变量的多项式形式作为预测变量得到了在 $X$ 取值空间全局皆非线性的拟合函数。如果不希望得到全局的模型，可以使用 <strong>阶梯函数</strong> 拟合。这里，把 $X$ 的取值范围分割成一些区间，每个区间上拟合一个不同的常数。这相当于 <strong>将一个连续变量转换成一个有序的分类变量</strong>。</p>

<p>具体来说，首先在 $X$ 取值空间上创建 $K$ 个分割点 $c_1,c_2,\dots,c_K$，然后构造以下 $K+1$ 个新变量：</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
C_0(X) &= I(X < c_1) \\[2ex]
C_1(X) &= I(c_1 \le X < c_2) \\[2ex]
C_2(X) &= I(c_2 \le X < c_3) \\[2ex]
&\; \vdots \\[2ex]
C_{K-1}(X) &= I(c_{K-1} \le X < c_K) \\[2ex]
C_K(X) &= I(c_K \le X)
\end{align} %]]></script>

<p>其中，$I(\cdot)$ 是指示函数，当条件成立时返回 $1$，否则返回 $0$。例如，当 $c_K \le X$ 时，$I(c_K \le X)$ 等于 $1$，否则等于 $0$。这样定义的变量有时候也称为 <strong>虚拟变量</strong>。注意，由于 $X$ 只能落在 $K + 1$ 个区间中的某一个，于是对任意 $X$ 的取值，都有 $C_0(X) + C_1(X) +\cdots + C_K(X) = 1$。然后，我们可以将 $C_1(X),C_2(X),\dots, C_K(X)$ 作为预测变量，使用最小二乘法来拟合一个线性模型：</p>

<script type="math/tex; mode=display">y_i = \beta_0 + \beta_1 C_1(x_i) + \beta_2 C_2(x_i) + \cdots + \beta_K C_K(x_i) +\epsilon_i</script>

<p>对于 $X$ 的一个给定值，$C_1(X),C_2(X),\dots, C_K(X)$ 中至多只有一项系数非零。注意到，当 $X &lt; c_1$ 时，式中的每个预测变量都为零，所以 $\beta_0$ 可以被解释为 $X &lt; c_1$ 时响应 $Y$ 的平均值。相应地，当 $c_j \le X &lt; c_{j+1}$ 时，响应的预测值为 $\beta_0 + \beta_j$，所以这里 $\beta_j$ 可以被解释为：当 $X$ 由 $X &lt; c_1$ 增至 $c_j \le X &lt; c_{j+1}$ 时，响应变量 $Y$ 的平均增量。</p>

<p>图 2 左图是以图 1 中的 <code class="language-plaintext highlighter-rouge">Wage</code> 数据拟合阶梯函数的效果。用 <code class="language-plaintext highlighter-rouge">wage</code> 对 <code class="language-plaintext highlighter-rouge">age</code> 拟合逻辑回归模型：</p>

<script type="math/tex; mode=display">\Pr(y_i > 250 \mid x_i) = \dfrac{\exp(\beta_0 + \beta_1 C_1(x_i) + \cdots + \beta_K C_K(x_i))}{1 + \exp(\beta_0 + \beta_1 C_1(x_i) + \cdots + \beta_K C_K(x_i))}</script>

<p>并用该模型预测一个样本属于高收入组的概率。图 2 右图显示使用这种方法得到的拟合后验概率。</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-11-09-WX20201110-014845%402x.png" width="80%" /></p>

<p><span style="margin:auto; display:table; font-size:10pt"> <span style="color:steelblue;font-weight:bold">图 1</span>：<code class="language-plaintext highlighter-rouge">Wage</code> 数据集。<strong>左图</strong>：实线表示用阶梯函数拟合 <code class="language-plaintext highlighter-rouge">wage</code> (单位：千美元) 关于 <code class="language-plaintext highlighter-rouge">age</code> 的最小二乘回归的结果；虚线为相应的 $95\%$ 置信区间。<strong>右图</strong>：使用阶梯函数，对二元变量 <code class="language-plaintext highlighter-rouge">wage &gt;250</code> 建立逻辑回归模型，实线表示 <code class="language-plaintext highlighter-rouge">wage &gt;250</code> 的后验概率，虚线为相应的 $95\%$ 置信区间。</span></p>

<p>但是，如果预测变量本身不具有明显的分割点，则不适用于分段固定值拟合。例如，图 2 左侧，在第一区间内 <code class="language-plaintext highlighter-rouge">wage</code> 随 <code class="language-plaintext highlighter-rouge">age</code> 本来应有的增长趋势没有得到体现。不过，阶梯函数拟合方法在生物统计和生态学等领域很受欢迎。例如，一些研究习惯将每五年作为一个年龄组来定义预测区间。</p>

<p>总的来说，阶梯函数方法易于使用。我们可以创建一系列虚拟变量来代表每个变量组。这对于创建易于解释的交互项非常有用。例如，我们可以创建关于 <code class="language-plaintext highlighter-rouge">year</code> 和 <code class="language-plaintext highlighter-rouge">age</code> 的交互作用：</p>

<script type="math/tex; mode=display">% <![CDATA[
I(\mathtt{year} < 2005)\cdot \mathtt{age},\quad I(\mathtt{year} \ge 2005)\cdot \mathtt{age} %]]></script>

<p>将允许不同年龄组拟合不同的线性函数。</p>

<p>在 R 中，可以使用 <code class="language-plaintext highlighter-rouge">I(year &lt; 2005)</code> 或者 <code class="language-plaintext highlighter-rouge">cut(age, c(18, 25, 40, 65, 90))</code> 完成。</p>

<p>但是，关于分割点或结点的选择可能是个问题。为了创建非线性，我们可以使用一些更平滑的替代方法，例如：样条方法。</p>

<h2 id="4-基函数">4. 基函数</h2>

<p>多项式和阶梯函数回归模型实际上是特殊的 <strong>基函数 (basis function)</strong> 方法。基本原理是对变量 $X$ 的函数或变换 $b_1(X),b_2(X),\dots,b_K(X)$ 进行建模。以模型</p>

<script type="math/tex; mode=display">y_i = \beta_0 + \beta_1 b_1(x_i) + \beta_2 b_2(x_i) + \beta_3 b_3(x_i) + \cdots + \beta_K b_K(x_i) +\epsilon_i</script>

<p>来替代线性模型。注意基函数 $b_1(\cdot),b_2(\cdot),\dots,b_K(\cdot)$ 的值是给定的而且是已知的 (也就是说，在建模之前就选定了基函数的形式)。例如，对于多项式回归来说，基函数就是 $b_j(x_i) = x_i^j$，而对于阶梯函数其基函数则为 $b_j(x_i) = I(c_j \le x_i &lt; c_{j+1})$。我们可以认为上面的式子就是以 $b_1(x_i),b_2(x_i),\dots,b_K(x_i)$ 为预测变量的标准线性模型。因此，可以使用最小二乘法来估计式中未知的回归系数。重要的是，这还表示之前我们所讨论的有关线性模型的各种推断结果，如标准误、系数估计值和用于模型整体显著性检验的 $F$ 统计量都可以使用。</p>

<p>到目前为止，多项式函数和阶梯函数都可以视为模型的基函数。其实，换成其他的基函数也是可以的。例如，可以用小波变换或傅立叶级数构建基函数。接下来，我们将探讨一类广泛采用的基函数：<strong>回归样条 (regression spline)</strong>。</p>

<h2 id="4-回归样条">4. 回归样条</h2>

<p>这里我们将讨论一类光滑的基函数，它是前面多项式回归和阶梯函数回归方法的延伸和推广。</p>

<h3 id="41-分段多项式">4.1 分段多项式</h3>

<p>相比在 $X$ 整个域上拟合一个高阶多项式，<strong>分段多项式回归 (Piecewise polynomial regression)</strong> 在由结点定义的 $X$ 的不同区域上拟合独立的低阶多项式函数。</p>

<p>例如，这里我们使用分段三次多项式函数来拟合下面的三次回归模型：</p>

<script type="math/tex; mode=display">y_i = \beta_0 + \beta_1 x_i + \beta_2 x_i^2 + \beta_3 x_i^3 + \epsilon_i</script>

<p>其中，系数 $\beta_0$、$\beta_1$、$\beta_2$ 和 $\beta_3 在 $X$ 的不同区域上是不相同的。系数发生变化的临界点称为 <strong>结点 (knots)</strong>。</p>

<p>例如，无结点的分段三次多项式就是上面式子中 $d=3$ 的标准三次多项式，</p>

<p>下节内容：非线性模型</p>
:ET