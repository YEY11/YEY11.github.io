I"8<!-- 数学公式 -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
  });
</script>

<h1 id="lecture-03-导论-3">Lecture 03 导论 (3)</h1>
<p>我们将用两周来回顾之前在 MAST90104 中学习过的线性模型的相关内容，上周我们已经回顾了包括如何拟合线性模型、如何解释线性模型等在内的一部分内容，本周我们将继续回顾线性模型中余下的内容。</p>

<p>在这节课中，我们将主要回顾以下内容：</p>
<ul>
  <li>线性模型中的假设检验</li>
  <li>线性模型中的置信区间</li>
  <li>模型诊断</li>
</ul>

<h2 id="7-线性模型中的假设检验">7. 线性模型中的假设检验</h2>
<h3 id="71-假设检验">7.1 假设检验</h3>
<p>假设检验可以用来决定一个线性模型中的预测变量 $X$ 组成的任何集合的显著性。</p>

<p>假设误差项 $\varepsilon_i$ 之间服从 i.i.d. 正态分布。</p>

<p>假设我们希望知道：在不损失较大的拟合优度的前提下，一个模型 $\Omega$ 是否可以用它的子模型 $\omega$ 来替代。而这可以通过假设检验来确认：</p>

<script type="math/tex; mode=display">H_0: \boldsymbol \beta_{\Omega-\omega}=\mathbf 0 \quad \text{vs.}\quad H_1: \boldsymbol \beta_{\Omega-\omega}\ne\mathbf 0</script>

<p>其中，$\boldsymbol \beta_{\Omega-\omega}$ 是参数 $\boldsymbol \beta$ 的一个子集，它存在于模型 $\Omega$ 中，但是不在其子模型 $\omega$ 中。</p>

<p>在线性模型中，我们希望知道预测变量的某个特定集合的显著性，我们希望知道这个预测变量的特定集合对于响应变量的效应。这可以通过构建两个模型来进行验证：模型 $\Omega$ 及其子模型 $\omega$。如果 $H_0$ 成立，说明两个模型之间的预测变量的差异构成的集合对于响应变量没有显著效应（即这部分预测变量的系数均为 $0$），因此，模型 $\Omega$ 可以用其子模型 $\omega$ 来替代。反之，如果 $H_1$ 成立，说明两个模型之间的预测变量的差异构成的集合对于响应变量有显著效应，我们不能用模型 $\omega$ 代替模型 $\Omega$。</p>

<p>假设样本数量为 $n$，模型 $\Omega$ 的参数数量为 $\text{dim}(\boldsymbol \beta_{\Omega})=p$，模型 $\omega$ 的参数数量为 $\text{dim}(\boldsymbol \beta_{\omega})=q$。那么当模型 $\omega$ 正确时（即 $H_0$ 为真），$F$ 统计量为：</p>

<script type="math/tex; mode=display">F=\dfrac{(\textsf{RSS}_{\omega}-\textsf{RSS}_{\Omega})\big /(p-q)}{\textsf{RSS}_{\Omega}\big /(n-p)}\,\sim \, F_{p-q,n-p}</script>

<p>如果 $F&gt;F_{p-q,n-p}^{(\alpha)}$，我们将在显著性水平 $\alpha$ 上拒绝 $H_0$ 假设。</p>

<p>这也被称为 <strong>方差分析检验（ANOVA test）</strong>。当然，在这两个模型中，模型 $\omega$ 的残差平方和要更大一些，因为它包含的参数数量更少。$F$ 统计量是由 R.A. Fisher 提出的，它告诉了我们从模型 $\Omega$ 转换到模型 $\omega$ 的过程中，残差平方和 $\textsf{RSS}$ 的相对减少量，如果这个减少量非常显著，则意味着当我们将包含全部参数的模型缩减为包含参数子集的模型时，被移除的那部分预测变量对于响应变量的效应实际上是非常显著的，因此，我们不能将其移除。</p>

<h3 id="72-假设检验的例子">7.2 假设检验的例子</h3>
<p>回忆之前我们之前讨论过的 2000 年美国总统大选时佐治亚州选票的例子，现在我们比较之前拟合的两个模型：$\omega=$<code class="highlighter-rouge">lmod</code> 和 $\Omega=$<code class="highlighter-rouge">lmodi</code>。其中，模型 $\omega$ 只包含 <code class="highlighter-rouge">pergore</code> 和 <code class="highlighter-rouge">perAA</code> 两个预测变量，而模型 $\Omega$ 增加了 <code class="highlighter-rouge">usage</code> 和 <code class="highlighter-rouge">equip</code>，以及一些交互项：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt; sumary(lmod)
            Estimate Std. Error t value Pr(&gt;|t|)
(Intercept) 0.032376   0.012761  2.5370  0.01216
pergore     0.010979   0.046922  0.2340  0.81531
perAA       0.028533   0.030738  0.9283  0.35470

n = 159, p = 3, Residual SE = 0.02445, R-Squared = 0.05


&gt; sumary(lmodi)
                      Estimate Std. Error t value  Pr(&gt;|t|)
(Intercept)          0.0432973  0.0028386 15.2529 &lt; 2.2e-16
cperAA               0.0282641  0.0310921  0.9090  0.364786
cpergore             0.0082368  0.0511562  0.1610  0.872299
usageurban          -0.0186366  0.0046482 -4.0095 9.564e-05
equipOS-CC           0.0064825  0.0046799  1.3852  0.168060
equipOS-PC           0.0156396  0.0058274  2.6838  0.008097
equipPAPER          -0.0090920  0.0169263 -0.5372  0.591957
equipPUNCH           0.0141496  0.0067827  2.0861  0.038658
cpergore:usageurban -0.0087995  0.0387162 -0.2273  0.820515

n = 159, p = 9, Residual SE = 0.02335, R-Squared = 0.17
</code></pre></div></div>

<p>我们可以通过 R 命令 <code class="highlighter-rouge">anova(model1, model2)</code> 完成 ANOVA 检验：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt; anova(lmod, lmodi)
Analysis of Variance Table

Model 1: undercount ~ pergore + perAA
Model 2: undercount ~ cperAA + cpergore * usage + equip
  Res.Df      RSS Df Sum of Sq      F   Pr(&gt;F)   
1    156 0.093249                                
2    150 0.081775  6  0.011474 3.5077 0.002823 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
</code></pre></div></div>

<p>计算得到的 $F$ 统计量为：</p>

<script type="math/tex; mode=display">F=\dfrac{(\textsf{RSS}_{\omega}-\textsf{RSS}_{\Omega})\big /(p-q)}{\textsf{RSS}_{\Omega}\big / (n-p)}=\dfrac{(0.093249-0.081775)\big /(9-3)}{0.081775\big /(159-9)}=3.5077 \,\sim\, F_{6,150}</script>

<p>这里，我们在模型 $\omega$ 中使用的是 <code class="highlighter-rouge">pergore</code> 和 <code class="highlighter-rouge">perAA</code>，而在模型 $\Omega$ 中我们对这两个变量进行了中心化，即 <code class="highlighter-rouge">cpergore</code> 和 <code class="highlighter-rouge">cperAA</code>。事实上，是否中心化对于残差平方和 RSS 没有影响，它们影响的其实是参数 $\boldsymbol \beta$ 的估计，所以在计算 $F$ 统计量时无需担心这一点。另外，可以看到 p 值为 $0.002823$，小于 $0.05$，因此我们拒绝 $H_0$ 假设。这意味着和模型 $\omega$ 相比，模型 $\Omega$ 多出来的 <code class="highlighter-rouge">usage</code>、<code class="highlighter-rouge">equip</code> 和 <code class="highlighter-rouge">cpergore:usage</code> 这几个预测变量对于响应变量的效应是比较显著的，我们应当拒绝模型 $\omega$。</p>

<p>因此，当我们希望检验 <strong>预测变量的某个集合</strong> 作用在响应变量上的效应时，可以采用 <strong>$F$ 检验</strong>。</p>

<p>而有些时候，我们只是希望检验 <strong>单个预测变量</strong> 对于响应变量的效应，我们当然还是可以使用一般的 $F$ 检验方法：拟合一个包含该预测变量的模型和一个不包含该预测变量的模型，并计算 $F$ 统计量。但是，非常重要的一点是我们需要知道模型中还包含哪些其他的预测变量，并且如果这些预测变量也发生了改变，那么结果可能会有所不同。</p>

<p>如果我们希望检验的这个 <strong>单独的预测变量</strong> 是 <strong>数值变量</strong> 时，我们可以用 <strong>$t$ 检验</strong> 替代。我们用以下假设来检验预测变量 $X_i$ 对于响应变量的效应：</p>

<script type="math/tex; mode=display">H_0:\beta_i=0 \quad \text{vs.}\quad H_1:\beta_i\ne 0</script>

<p>在 $H_0$ 假设下，$t$ 统计量为：</p>

<script type="math/tex; mode=display">t_i=\hat{\beta}_i \big / \textrm{se}(\hat{\beta}_i)\,\sim\, t_{n-p}</script>

<p>注意，这里 $t$ 检验和 $F$ 检验实际上是等价的：$t_{n-p}^2=F_{1,n-p}$</p>

<p>这种方法得到的 p 值和 $F$ 检验中得到的完全一样。例如，在模型 <code class="highlighter-rouge">lmodi</code> 中，非裔美国人占比 <code class="highlighter-rouge">cperAA</code> 的显著性给出的 p 值为 $0.364786$。这表明在调整其他预测变量对响应变量的效应之后，<code class="highlighter-rouge">cperAA</code> 这个预测变量并不具有统计显著性。</p>

<p>注意，通常我们应该避免将 $t$ 检验应用于包含 $2$ 个以上 levels 的 <strong>分类变量</strong>。因为对于一个包含 $2$ 个以上 levels 的分类变量，我们需要不止一个虚拟变量来编码这个分类变量（例如：对于一个包含 $3$ 个 levels 的分类变量，我们需要用 $2$ 个虚拟变量来编码它），这意味着我们实际上检验的预测变量的数量不止一个，在这种情况下，我们应该使用 $F$ 检验而不是 $t$ 检验。</p>

<p>在 R 中，我们可以使用 <code class="highlighter-rouge">drop1(model, test="F")</code> 来实现对于单个预测变量的 $F$ 检验，它每次从原始模型中移除 1 个预测变量，来检验这种移除对于响应变量的效应的显著性：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt; drop1(lmodi, test="F")
Single term deletions

Model:
undercount ~ cperAA + cpergore * usage + equip
               Df Sum of Sq      RSS     AIC F value  Pr(&gt;F)  
&lt;none&gt;                      0.081775 -1186.1                  
cperAA          1 0.0004505 0.082226 -1187.2  0.8264 0.36479  
equip           4 0.0054438 0.087219 -1183.8  2.4964 0.04521 *
cpergore:usage  1 0.0000282 0.081804 -1188.0  0.0517 0.82051  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
</code></pre></div></div>

<p>可以看到，移除 <code class="highlighter-rouge">cperAA</code> 对应的 p 值为 $0.36479&gt;0.05$，此时我们接受 $H_0$，即可以认为 <code class="highlighter-rouge">cperAA</code> 这个预测变量对于响应变量的效应不具有统计显著性，我们可以将其移除，这和我们之前在 $t$ 检验中得到的结论是一致的。而对于分类变量 <code class="highlighter-rouge">equip</code>，它包含 $5$ 个 levels，所以我们用 $4$ 个虚拟变量来编码它，如果我们将它移除，可以看到对应的 p 值为 $0.04521&lt;0.05$，此时我们拒绝 $H_0$ 假设，这意味着 <code class="highlighter-rouge">equip</code> 这个分类变量对于响应变量的效应具有统计显著性，我们不应该将其移除。同理，交互项 <code class="highlighter-rouge">cpergore:usage</code> 对应的 p 值为 $0.82051&gt;0.05$，我们可以将其移除。</p>

<p>另外，我们注意到在原始模型中一共有 5 个预测变量，而在这里只尝试移除了其中的 3 个，<code class="highlighter-rouge">drop1</code> 命令并没有对单独的 <code class="highlighter-rouge">cpergore</code> 和 <code class="highlighter-rouge">usage</code> 进行检验，因为这里涉及到一个隐式的原则，我们称之为 <strong>等级原则（hierarchy principle）</strong>：一个交互项对应的所有低阶项都应当被保留在模型中。也就是说，无论交互项 <code class="highlighter-rouge">cpergore:usage</code> 对于响应变量是否具有显著效应，其对应的预测变量 <code class="highlighter-rouge">cpergore</code> 和 <code class="highlighter-rouge">usage</code> 在这里都不会被移除。所以，接下来我们需要对移除交互项 <code class="highlighter-rouge">cpergore:usage</code> 之后的模型再进行一次 <code class="highlighter-rouge">drop1</code> 检验。</p>

<p>在解释假设检验的结果时存在很多困难，其中可能涉及到一些操作顺序导致的误差，在真正理解问题之前，我们需要避免只是简单地从字面上解读这些结果。</p>

<h2 id="8-线性模型中的置信区间">8. 线性模型中的置信区间</h2>
<p>对于模型参数 $\boldsymbol \beta$ 中的任何一个元素，我们都可以得到一个对应的置信区间：</p>

<script type="math/tex; mode=display">\hat{\beta}_j\pm t_{n-p}^{(\alpha/2)}\textrm{se}(\hat{\beta}_j)</script>

<p>其中，$t_{n-p}^{(\alpha/2)}$ 是一个自由度为 $(n-p)$ 的 $t$ 分布中的上 $(\alpha/2)$ 分位数。</p>

<p>注意：这样一个 $t$ 置信区间是基于线性模型的正态假设得到的。如果正态假设不能满足，那么我们会将 $t$ 区间替换为渐进正态区间。</p>

<p>在 R 中，使用 <code class="highlighter-rouge">confint(model)</code> 命令可以查看模型中各个参数项的置信区间：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt; confint(lmodi)
                            2.5 %       97.5 %
(Intercept)          0.0376884415  0.048906189
cperAA              -0.0331710614  0.089699222
cpergore            -0.0928429315  0.109316616
usageurban          -0.0278208965 -0.009452268
equipOS-CC          -0.0027646444  0.015729555
equipOS-PC           0.0041252334  0.027153973
equipPAPER          -0.0425368415  0.024352767
equipPUNCH           0.0007477196  0.027551488
cpergore:usageurban -0.0852990903  0.067700182
</code></pre></div></div>

<p>从参数项的置信区间中，我们可以得到和之前假设检验对于同一个参数检验结果的等价结论。例如：对于变量 <code class="highlighter-rouge">usageurban</code>，它是预测变量 <code class="highlighter-rouge">usage</code> 编码后的一个虚拟变量，它对应的参数 $\beta_{\text{usageurban}}$ 的 $95\%$ 置信区间为 $(-0.0278208965,-0.009452268)$，可以看到 $0$ 并不在这个区间内，这意味着我们将在 $5\%$ 的显著性水平上拒绝假设 $H_0:\beta_{\text{usageurban}}=0$。同理，对于 <code class="highlighter-rouge">cperAA</code>，$0$ 包含在其置信区间中，因此我们不拒绝 $H_0:\beta_{\text{cperAA}}=0$。</p>

<p>置信区间和对应的 $t$ 检验之间存在一种等价效应，我们称之为 <strong>对偶性（duality）</strong>：</p>

<p>下节内容：导论 (4)</p>
:ET