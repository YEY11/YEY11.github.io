I"M<!-- 数学公式 -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
  });
</script>

<h1 id="论文阅读-01-the-case-for-learned-index-structures">论文阅读 01 The Case for Learned Index Structures</h1>

<p><strong>标题：</strong> The Case for Learned Index Structures<br />
<strong>作者：</strong> Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, Neoklis Polyzotis<br />
<strong>时间：</strong> 2018.04<br />
<strong>地址：</strong> <a href="https://arxiv.org/abs/1712.01208">https://arxiv.org/abs/1712.01208</a></p>

<h2 id="摘要">摘要</h2>
<p><strong>传统的索引模型可以分为以下 3 类：</strong></p>
<ul>
  <li><strong>B 树（B-Trees）</strong>：可以视为一个模型，它将一个键值 Key 映射到一个有序数组中的一条记录的位置。通常用于范围查询（例如检索特定时间范围内的所有记录）。</li>
  <li><strong>哈希映射（Hash-maps）</strong>：可以视为一个模型，它将一个键值 Key 映射到一个无序数组中的一条记录的位置。通常用于单键值查找。</li>
  <li><strong>比特映射索引（BitMap-Index）</strong>：可以视为一个模型，用于检查一条数据记录是否存在。（例如：Bloom ﬁlters）</li>
</ul>

<p>在本文中，假设所有现存的索引结构都可以替换为其他类型的模型，包括深度学习模型，我们称之为 <strong>学习索引（learned index）</strong></p>

<p><strong>关键思想</strong>：一个模型可以学习排序顺序或者查询键值的结构，并且利用这类信息来高效预测记录的位置或者判断记录是否存在。</p>

<p>文章从理论上分析了在什么情况下，学习索引的表现优于传统索引，以及设计学习索引结构时的一些主要挑战。文章初步结果显示，在几个真实数据集上，基于神经网络的学习索引在速度上要比经过缓存优化的 B 树快 70%，并且在内存方面要节省一个数量级。更重要的是，作者认为这种利用学习模型替换数据管理系统中的核心组件的想法对于未来的系统设计具有潜在的长远影响。</p>

<h2 id="1-导论">1. 导论</h2>
<p><strong>传统索引结构的缺点</strong>：没有对数据本身的分布作出任何假设，并且也没有利用现实世界中普遍存在的一些更常见模式的优势。</p>

<p>在知道确切的数据分布的前提下，我们几乎可以对任何索引结构进行高度优化。</p>

<p>当然，在现实世界中大部分情况下，数据不会完美服从某个已知分布，而且针对每个用例构建特定的解决方案会导致巨大的工程量。但是，作者认为机器学习可以让我们以较低的工程成本自动合成所谓 <strong>“学习索引”</strong> 的特殊索引结构。</p>

<p>本文作者探索了（包括神经网络在内的）学习索引可以用于提升、甚至替换传统索引（从 B 树到布隆过滤器）。</p>

<p>在语义学方面，索引在很大程度上已经可以被视为 <strong>学习模型</strong> 了。这使得我们用其他机器学习模型对其进行替换时比预期的更容易。例如：B 树可以视为一个模型，输入为 key，预测为一个有序集合中的某条数据的位置；而布隆过滤器则可以视为一个二分类模型，预测一个集合中的某个 key 是否存在。但是，它们和真正的学习模型还存在一些微妙的但非常重要的差异，例如：一个布隆过滤器可以只有假阳例，而没有假阴例。</p>

<p>在性能方面，由于每个CPU都具有强大的SIMD功能，可以合理推测越来越多的设备将拥有图形处理单元（GPU）或张量处理单元（TPU），并且功能将越来越强大。因为对于神经网络使用的（并行）数学运算受限集的扩展要比通用指令集的扩展容易得多。因此，执行神经网络的高成本在未来实际上可以忽略不计。</p>

<p>很重要的一点是，作者并不主张使用学习索引来完全取代传统的索引结构。相反，本文主要贡献在于提出了一种建立索引的新方法，并对其进行了评估。它作为现有工作的补充，为这一领域开辟了一个新的研究方向。虽然本文专注于分析只读工作负载，但是作者也简单概述了如何将其扩展到涉及频繁写入工作负载的任务。此外，作者还简要概述如何使用相同的原则来替换数据库及其他组件的操作，包括排序和联表 (join)。这些可能会在未来引领一种全新的数据库的开发方式。</p>

<h2 id="2-范围索引">2. 范围索引</h2>
<p>范围索引结构（例如：B 树）可以视为一种模型：给定一个键（key），“预测” 一个基于 key 的有序集合中某个值的位置。如图 1 中的（a）所示，B 树提供了一种从查找键（look-up keys） 到存储记录（records）的有序数组内某个位置（position）的映射，并且保证该位置的那条记录对应的 key 是第一个等于或者大于查找键的 key。注意，必须对数据进行排序以允许范围请求。相同的概念也适用于二级索引，此时数据为 key-记录指针对 <script type="math/tex">% <![CDATA[
\text{<key, record pointer>} %]]></script> 的列表。</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-04-12-WX20200412-161543%402x.png" width="80%" /></p>

<p><strong><center><span style="font-size:10pt">图 1. 为什么 B 树可以视为模型</span></center></strong></p>

<p>出于效率原因，通常不会对已排序记录的每个单独的 key 进行索引，而是对每隔 n 条记录对应的 key 进行索引，即每个页（page）的第一个 key。这里仅仅假设固定长度记录，以及在一块连续内存区域上逻辑分页（logical paging）的情况，即一个单独的 <strong>数组</strong>，而非分散在不同内存区域上的物理页。仅仅对每个 page 的第一个 key 进行索引，可以在没有明显性能损失的前提下，显著减少必须存储的 keys 的数量。因此，B 树可以视为一个 <strong>回归树模型：它将一个 key 映射到一个位置的最小和最大误差之间</strong>（最小误差为 0，最大误差为一个 page 的大小），这可以保证只要这个 key 存在，那么一定可以在该范围内找到它。按照这种思路，我们可以用其他机器学习模型（包括神经网络）替代 B 树索引，只要其能够提供类似的有关最小误差和最大误差的有力保证。</p>

<p>实际上，为其他 ML 模型提供相同错误保证这件事要比看起来简单。<strong>首先，B 树仅为存储的 keys，而非所有可能的 keys，提供这种关于最小最大误差的有力保证。</strong>对于新数据，B 树需要进行重新平衡，或者对应于机器学习中的重新训练，来提供相同的误差保证。也就是说，对于单调模型，我们唯一要做的就是利用模型对每一个 key 进行预测，并且记下对于一个位置的最差的过高和过低的预测，来计算最小和最大误差。其次，更重要的一点是，我们甚至 <strong>不需要强的误差边界</strong>。因为为了支持范围请求，数据总是会进行排序，所以，任何误差都可以通过在预测位置附近进行 <strong>局部搜索</strong> 来纠正。因此，甚至可以扩展到非单调模型。所以，我们可以用任何其他类型的回归模型，例如线性回归或者神经网络，来替代 B 树。</p>

<p>要实现这种替换还存在一些其他挑战。例如，B 树对于插入和查找都有一个有界代价，并且能够很好地利用缓存（cache）的优势。此外，B 树还可以将 keys 映射到那些分散在非连续内存或者磁盘中的页（pages）。</p>

<p>同时，使用其他模型替代索引可以带来极大的好处。最主要的一点就是这种做法有潜力 <strong>将时间复杂度为 $O(\log n)$ 的 B 树查找转换为一个常数时间操作 $O(1)$</strong>。机器学习（尤其是神经网络）的优势在于它们能够学习各种各样的数据分布/混合和其他数据特征和模式。显然，挑战在于 <strong>平衡模型的复杂度与准确性</strong>。</p>

<h3 id="21-我们可以接受的模型复杂度">2.1 我们可以接受的模型复杂度</h3>

<p>为了更好地理解模型的复杂度，我们需要知道在和遍历 B 树所需的相同时间内，模型可以执行的操作次数，以及学习索引需要达到什么样的精度才能在查找效率上超过 B 树。</p>

<p>考虑一个索引 $100M$ 记录、page 大小为 $100$ 的 B 树。我们可以将 B 树的每一个结点视为一种空间划分方式，以减小 “误差” 、缩小范围，从而找到数据。所以，对于一个 page 大小为 $100$ 的 B 树，每个结点的精度增益（precision gain）都是 $1/100$，总共需要遍历 $\log_{100}N$ 个结点。因此，第一个结点将查找空间从 $100M$ 缩小到 $100M/100=1M$，第二个结点从 $1M$ 缩小到 $1M/100=10k$，以此类推，直到找到记录。现在，采用二分查找对一个 B 树的单个 page 进行遍历大约需要 50 个时钟周期，并且非常难以实现并行化。相比之下，现在 CPU 可以在每个周期执行 8-16 次 SIMD 操作。因此，只要一个模型在每 $50\times8=400$ 次算术运算的精度增益超过 $1/100$，它就可以在查找速度上超过 B 树。注意，这种计算方法仍然是假定所有的 B 树 pages 都在缓存中。单个的缓存缺失（cache-miss）会消耗 50-100 个额外的时钟周期，因此可以允许更复杂一些的模型。</p>

<p>此外，机器学习允许在相同的时间内运行更复杂的模型，并且将计算任务从 CPU 转移到 GPU/TPU上。尽管作者认为 GPU/TPU 是实践中采用学习索引的主要原因之一，但本文仍然将重点放在性能有限的 CPU 上，以便在不考虑硬件因素的前提下，更好地研究通过机器学习替换和增强索引的影响。</p>

<h3 id="22-范围索引模型是-cdf-模型">2.2 范围索引模型是 CDF 模型</h3>

<p>如前所述，索引是一个模型，它接受一个 key 作为输入并预测某条记录的位置。虽然对于单点查询，记录的顺序并不重要，但是对于范围查询，必须根据 look-up key 对数据进行排序，使得所有数据项都在一个范围内。这导致了一个有趣的观察：对于一个通过给定 key 来预测有序数组中的某个位置的模型，它可以有效近似为累积分布函数（CDF）。我们可以对数据的 CDF 建模来预测位置：</p>

<script type="math/tex; mode=display">p=F(\text{Key})*N \tag{1}</script>

<p>其中，$p$ 是位置估计；$F(\text{Key})$ 是数据的估计的 CDF，用来估计一个 key 小于或者等于 look-up key 的似然，即 $P(X\le \text{Key})$；$N$ 是 key 的总数量。</p>

<p><a name="fig2"><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-04-13-WX20200413-161527%402x.png" width="70%" /></a></p>

<p><strong><center><span style="font-size:10pt">图 2. 范围索引是 CDF 模型</span></center></strong></p>

<p>这带来了一些新方向：</p>
<ol>
  <li>这意味着从字面上看，索引需要学习数据分布。
    <ul>
      <li>例如：B 树通过构建回归树来 “学习” 数据分布；而线性回归模型则通过最小化线性函数的（平方）误差来学习数据分布。</li>
    </ul>
  </li>
  <li>估计数据集的分布是一个被广泛研究过的问题，学习索引可以从之前数十年的研究中受益。</li>
  <li>学习 CDF 在优化其他类型的索引结构和潜在算法时，也有着非常重要的作用。</li>
  <li>已有大量关于理论 CDF 和经验 CDF 近似的研究，这为理解学习索引的好处提供了理论支撑。</li>
</ol>

<h3 id="23-朴素学习索引naive-learned-index">2.3 朴素学习索引（Naive Learned Index）</h3>

<p>为了更好地理解用学习索引取代传统B树有哪些技术要求，我们使用了 $200M$ 的 Web 服务器日志记录，目标是使用 Tensorflow 在时间戳上建立一个二级索引：</p>

<ul>
  <li>架构：2 层的全连接神经网络，每层 32 个神经元</li>
  <li>激活函数：ReLU</li>
  <li>输入特征：时间戳</li>
  <li>输出标签：有序数组中的位置</li>
</ul>

<p>之后，使用 Tensorflow 和 Python 作为前端，随机选择一个 key，测量查找时间（运行多次取平均值，除去开始的几次）。在这种情况下，实现了每秒大约 1250 次预测，即，在不包括搜索时间（从预测位置到真实位置所花的查找时间）的情况下，使用 Tensorflow 执行模型需要大约 80,000 纳秒（ns）。相比之下，B 树遍历同样数据只需要大约 300 ns，而二分查找则需要大约 900 ns。其原因是多方面的：</p>

<ol>
  <li>Tensorflow 主要是用来运行大型模型的，而非小模型，因此会产生明显的调用开销，尤其是使用 Python 作为前端时。</li>
  <li>B树，或者一般意义上的决策树，使用少量的操作就很容易过拟合数据，因为它们使用简单的 if 语句递归地分割空间。相比之下，其他模型可以明显更有效地近似 CDF 的总体形状，但在单个数据实例级别的精确定位上存在一些问题。从 <a href="#fig2">图 2</a> 中可以看到，宏观上，CDF 函数看起来非常平滑和规律。但是，如果放大到单条记录的层面，就能看到越来越多的不规律之处; 这是一个众所周知的统计效应。因此，像神经网络、多项式回归等模型可能会以较高的 CPU 和空间效率从整个数据集缩小到仅包含数千条记录的范围，但是，单个神经网络通常需要更多的空间和 CPU 时间来完成 “最后一公里”：将误差从数千条缩小到数百条的范围。</li>
  <li>B 树具有极高的缓存效率和操作效率，因为它们总是将顶层结点保留在缓存中，并且在需要时访问其他 pages。相比之下，标准的神经网络在计算预测时需要知道所有的权重，这会带来很大的乘法运算开销。</li>
</ol>

<h2 id="3-rm-索引recursive-model-index">3. RM 索引（Recursive Model Index）</h2>
<p>为了克服这些挑战，并探索模型作为索引替代或者优化的潜力，作者开发了 <strong>学习索引框架（LIF）</strong>、<strong>递归模型索引（RMI）</strong>和 <strong>基于标准误的搜索策略</strong>。出于简洁性和灵活性的考虑，作者将主要关注简单的全连接神经网络，但是，作者也相信其他类型的模型可能也会带来一些额外的好处。</p>

<h3 id="31-学习索引框架lif">3.1 学习索引框架（LIF）</h3>
<p>LIF 可以被视为一个索引合成系统；给定一个索引规范，LIF 将生成不同的索引配置，并且对其进行优化和自动化测试。尽管 LIF 可以学习简单模型（例如：线性回归模型），但其依赖的 Tensorflow 主要是面向更加复杂模型的（例如：神经网络）。但是，它永远不会使用 Tensorflow 进行推断。相反，给定一个训练好的 Tensorflow 模型，LIF 会自动从模型中提取所有权重，并根据模型规范在 C++ 中生成高效的索引结构。我们的代码生成专注于小型模型，并且移除了 Tensorflow 在管理大模型所需的所有不必要开销。我们参考了 [25] 的思路，其展示了如何避免在 sprak 运行时的不必要开销。结果，我们可以在 30 ns 的数量级上执行简单模型。</p>

<p>然而，必须指出的是 LIF 仍然是一个实验性的框架，并且被工具化用于快速评估不同的索引配置（例如：机器学习模型、page 大小、搜索策略等），这引入了以加法计数器、虚拟函数调用等形式的额外开销。另外，除了编译器完成向量化之外，我们并没有使用特殊的 SIMD 指令集。尽管这些低效的做法并不影响我们的评估因为我们在框架中确保了公平的比较方式，但是在生产设定下或者将其与其他实现方式下的报告中的性能数字进行对比时，则必须对这种低效性进行考虑/避免。</p>

<h3 id="32-递归模型索引">3.2 递归模型索引</h3>
<p>正如在 2.3 中提到的，构建一个替代 B 树的学习模型的关键挑战在于最后一英里搜索的准确性。例如，利用单个模型将预测误差从 $100M$ 条记录减小到几百条的数量级通常是非常困难的。同时，将误差从 $100M$ 减小到 $10k$ 则要简单得多（例如，通过利用一个模型来替换 B 树中的前两层来达到 $100\times 100=10000$ 的精度增益），哪怕是采用非常简单的模型。类似地，将误差从 $10k$ 减小到 $100$ 同样是一个更加简单的问题，因为模型只需要关注整个数据集的一个子集。</p>

<p><a name="fig3"><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-04-13-WX20200413-212845%402x.png" width="80%" /></a></p>

<p><strong><center><span style="font-size:10pt">图 3. 阶段模型</span></center></strong></p>

<p>基于上述观察，作者提出了 <a href="#fig3">图 3</a> 所示的递归回归模型。也就是说，作者构建了一个分级模型，在每个阶段，模型接受一个 key 作为输入，并基于它选择下一个模型，直到最终阶段预测出位置。更为正式的表述是，对于模型 $f(x)$，其中 $x$ 是 key，$y\in [0,N)$ 位置，假设在阶段 $\ell$ 有 $M_{\ell}$ 个模型。我们在阶段 $0$ 训练模型 $f_0(x)\approx y$。因此，阶段 $\ell$ 的模型 $k$ 可以表示为 $f_{\ell}^{(k)}$，其训练采用的损失函数为：</p>

<script type="math/tex; mode=display">L_{\ell}=\sum_{(x,y)}(f_{\ell}^{(\lfloor M_{\ell}f_{\ell-1}(x)/N \rfloor)}(x)-y)^2 \qquad \qquad L_0=\sum_{(x,y)}(f_0(x)-y)^2</script>

<p>注意，这里表示 $f_{\ell-1}(x)$ 将递归执行 $f_{\ell-1}(x)=f_{\ell-1}^{(\lfloor M_{\ell-1}f_{\ell -2}(x)/N \rfloor)}(x)$。总的来说，我们利用损失函数 $L_{\ell}$ 对每个阶段进行迭代训练从而构建出完整的模型。一种理解这些不同模型的方法是，对于给定的 key，每个模型都给出了一个包含特定误差的关于记录位置的预测，并且预测结果被用来选择下一个模型，而下一个模型需要对一个特定范围的 key 空间给出一个具有更小误差的更好的预测。但是，递归模型索引不需要是树，如 <a href="#fig3">图 3</a> 所示，某个阶段的不同模型可能会选择下一个阶段的同一个模型。并且，每个模型并不需要像 B 树一样包含相同数量的记录（例如：一个 page 大小为 $100$ 的 B 树将包含 $100$ 条或者更少的数据）。最后，取决于所使用的模型，不同阶段之间的预测不一定需要解释为位置估计，而是应当被视为挑选一个对于特定的 keys 有更好了解的专家。</p>

<p>该模型架构具有诸多好处：</p>
<ol>
  <li>它将模型大小与复杂度从执行开销中分离出来。</li>
  <li>它利用了其易于学习数据分布的总体形状的事实。</li>
  <li>它有效地将空间划分成了更小的子范围（就像 B 树一样），这使得以更少的操作达到所需的 “最后一英里” 准确性更容易。</li>
  <li>在各阶段之间不需要搜索过程。</li>
</ol>

:ET