I"×l<h1 id="lecture-09-å¹¿ä¹‰çº¿æ€§æ¨¡å‹glm">Lecture 09 å¹¿ä¹‰çº¿æ€§æ¨¡å‹ï¼ˆGLMï¼‰</h1>
<p>æˆ‘ä»¬å·²ç»è§è¿‡äº†å¹¿ä¹‰çº¿æ€§æ¨¡å‹çš„ä¸€äº›ç‰¹ä¾‹ï¼Œå…¶ä¸­ï¼Œå“åº”å˜é‡ $Y$ æœä»ä¼¯åŠªåˆ©åˆ†å¸ƒã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥çœ‹ä¸€ä¸‹æ›´åŠ å¹¿ä¹‰çš„æƒ…å†µï¼Œå“åº”å˜é‡ $Y$ ä¸å†æ˜¯æ­£æ€çš„ã€‚æœ¬ç« å°†åŒ…å«ä»¥ä¸‹ä¸‰éƒ¨åˆ†ï¼š</p>

<ul>
  <li>ä»‹ç»</li>
  <li>ä¼°è®¡</li>
  <li>æ¨æ–­</li>
</ul>

<h2 id="1-ä»‹ç»">1. ä»‹ç»</h2>
<p>ä»¤ $Y_1,Y_2,\dots,Y_n$ ä¸ºéšæœºå˜é‡ $Y$ çš„ç‹¬ç«‹è§‚æµ‹ï¼Œå…¶å…³è”çš„åå˜é‡å‘é‡ä¸º $\mathbf x_1,\mathbf x_2,\dots,\mathbf x_n$ã€‚</p>

<p>å¦‚æœéšæœºå˜é‡ $Y$ çš„è¿™äº›ç‹¬ç«‹è§‚æµ‹æœä»æ­£æ€åˆ†å¸ƒï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥é‡‡ç”¨çº¿æ€§æ¨¡å‹æ¥å»ºç«‹éšæœºå˜é‡ $Y$ å’Œå…¶å…³è”çš„åå˜é‡ä¹‹é—´çš„è”ç³»ã€‚å¯¹äº $i=1,\dots,n$ï¼Œæˆ‘ä»¬æœ‰</p>

\[Y_i\overset{\mathrm{d}}{=}N(\mu_i,\sigma^2) \quad \text{å½¼æ­¤ç‹¬ç«‹ï¼Œå¹¶ä¸”} \quad \mu_i=\mathbf x_i^{\mathrm{T}}\boldsymbol \beta\]

<p>å…¶ä¸­ï¼Œå“åº”å˜é‡ $Y_i$ çš„æœŸæœ› $\mu_i$ æ˜¯å…³äºåå˜é‡ $\mathbf x_i$ çš„çº¿æ€§å‡½æ•°ã€‚</p>

<p>ç°åœ¨ï¼Œæˆ‘ä»¬è¯•å›¾å°†è¯¥æ¨¡å‹ä»æ­£æ€åˆ†å¸ƒæ¨å¹¿åˆ° <strong>æŒ‡æ•°æ—ï¼ˆexponential famil yï¼‰</strong> åˆ†å¸ƒï¼šæˆ‘ä»¬å‡è®¾</p>

\[Y_i\overset{\mathrm{d}}{=}\mathcal {EF}(\mathrm{mean}=\mu_i)  \quad \text{å½¼æ­¤ç‹¬ç«‹ï¼Œå¹¶ä¸”} \quad g(\mu_i)=\eta_i=\mathbf x_i^{\mathrm{T}}\boldsymbol \beta\]

<p>å…¶ä¸­ï¼Œ$\eta_i=\mathbf x_i^{\mathrm{T}}\boldsymbol \beta$ æ˜¯ <strong>çº¿æ€§é¢„æµ‹å˜é‡ï¼ˆlinear predictorï¼‰</strong>ã€‚</p>

<p>å‡½æ•° $g(.)$ è¢«ç§°ä¸º <strong>è¿æ¥å‡½æ•°ï¼ˆlink functionï¼‰</strong>ï¼šå®ƒæä¾›äº†çº¿æ€§é¢„æµ‹å˜é‡å’Œå“åº” $Y$ çš„å‡å€¼ä¹‹é—´çš„è¿æ¥ã€‚</p>

<p>å¦‚æœ $g(\mu_i)$ è¢«è®¾ç½®ä¸ºç­‰äºæŒ‡æ•°æ—ä¸­çš„ <strong>å…¸èŒƒå‚æ•°ï¼ˆcanonical parameterï¼‰</strong>ï¼Œåˆç§° <strong>è‡ªç„¶å‚æ•°ï¼ˆnatural parameterï¼‰</strong>ï¼Œé‚£ä¹ˆï¼Œ$g(.)$ è¢«ç§°ä¸º <strong>è‡ªç„¶è¿æ¥ï¼ˆnatural linkï¼‰</strong> æˆ–è€… <strong>å…¸èŒƒè¿æ¥ï¼ˆcanonical linkï¼‰</strong>ã€‚</p>

<p><br /></p>

<p>å¦‚æœ $Y$ çš„åˆ†å¸ƒæ˜¯ <strong>å…¸èŒƒå½¢å¼ï¼ˆcanonical formï¼‰</strong>ï¼Œé‚£ä¹ˆï¼Œå®ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆpdfï¼‰$f(y\mid \theta,\phi)$ æ»¡è¶³</p>

\[\ln f(y\mid \theta,\phi)=\dfrac{y\theta-b(\theta)}{a(\phi)}+c(y,\phi)\]

<p>å…¶ä¸­ï¼Œ$\theta$ è¢«ç§°ä¸º <strong>å…¸èŒƒå‚æ•°ï¼ˆcanonical parameterï¼‰</strong>æˆ–è€… <strong>è‡ªç„¶å‚æ•°ï¼ˆnatural parameterï¼‰</strong>ï¼Œä»£è¡¨äº† <strong>ä½ç½®ï¼ˆlocationï¼‰</strong>ï¼›è€Œ $\phi$ è¢«ç§°ä¸º <strong>æ•£å¸ƒå‚æ•°ï¼ˆdispersion parameterï¼‰</strong>ï¼Œä»£è¡¨äº† <strong>å°ºåº¦ï¼ˆscaleï¼‰</strong>ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æŒ‡å®šå‡½æ•° $a,b,c$ æ¥å®šä¹‰ä¸åŒçš„æŒ‡æ•°æ—åˆ†å¸ƒã€‚é€šå¸¸ï¼Œ$a(\phi)=\phi \big/ w$ï¼Œå…¶ä¸­ï¼Œ$w$ æ˜¯å·²çŸ¥çš„ <strong>æƒé‡ï¼ˆweightï¼‰</strong>ã€‚</p>

<p>å¯ä»¥æ¨å¯¼å‡º</p>

\[\dfrac{\partial \ln f(y\mid \theta,\phi)}{\partial \theta}=\dfrac{y-b'(\theta)}{a(\phi)}\;, \qquad \dfrac{\partial^2 \ln f(y\mid \theta,\phi)}{\partial \theta^2}=-\dfrac{b''(\theta)}{a(\phi)}\]

<p><br /></p>

<p>å¦ä¸€æ–¹é¢ï¼Œ</p>

\[\begin{align}
\mathbb{E}\left[\dfrac{\partial \ln f(y\mid \theta,\phi)}{\partial \theta} \right] &amp;= \int \dfrac{\partial \ln f(y\mid \theta,\phi)}{\partial \theta} \cdot f(y\mid \theta,\phi)dy\\
&amp;=\dfrac{\partial}{\partial \theta}\int f(y\mid \theta,\phi)dy=\dfrac{\partial}{\partial \theta}1=0\\\\

\mathbb{E}\left[\dfrac{\partial^2 \ln f(y\mid \theta,\phi)}{\partial \theta^2} \right] &amp;= \int \dfrac{\partial}{\partial \theta} \left(\dfrac{f_{\theta}'(y\mid \theta,\phi)}{f(y\mid \theta,\phi)} \right)\cdot f(y\mid \theta,\phi)dy\\
&amp;= \int f_{\theta}''(y\mid \theta,\phi)dy-\int \left(\dfrac{\partial \ln f(y\mid \theta,\phi)}{\partial \theta}\right)^2 f(y\mid \theta,\phi)dy\\
&amp;= 0-\mathbb{E}\left[\left(\dfrac{\partial \ln f(y\mid \theta,\phi)}{\partial \theta} \right)^2\right]
\end{align}\]

<p>æ³¨æ„ï¼Œè¿™é‡Œæœ‰ä¸ªæŠ€å·§æ˜¯åˆ©ç”¨ $(\ln f)â€™=fâ€™\big/f$ çš„æ€§è´¨ã€‚</p>

<p><br /></p>

<p>ç»“åˆä¸Šé¢çš„æ¨å¯¼ï¼Œå¯ä»¥å¾—åˆ°</p>

\[\mu=\mathbb{E}(Y)=b'(\theta)\;, \qquad \sigma^2=\mathrm{var}(Y)=a(\phi)b''(\theta)\]

<ul>
  <li>
    <p><strong>ä¾‹å­ï¼šæ³Šæ¾åˆ†å¸ƒ</strong><br />
å¦‚æœ $Y\overset{\mathrm d}{=}\mathrm{Poi}(\lambda)$ï¼Œé‚£ä¹ˆ $\ln f(y\mid \lambda)=-\lambda + y\ln \lambda - \ln y!$ï¼Œæ‰€ä»¥ $\theta=\ln \lambda$ã€‚</p>

    <p>å› æ­¤ï¼Œæˆ‘ä»¬æœ‰ $\ln f(y\mid \lambda)=-e^{\theta}+y\theta-\ln y!$ï¼›æ‰€ä»¥ï¼Œ$b(\theta)=e^{\theta}$ï¼Œå¹¶ä¸” $a(\phi)=1$ã€‚</p>

    <p>ç”±ä¸Šé¢çš„ç»“æœå¯å¾—</p>

\[\begin{align}
\mu &amp;= \mathbb{E}(Y)=b'(\theta)=e^{\theta}=\lambda \\\\
\sigma^2 &amp;= \mathrm{var}(Y)=a(\phi)b''(\theta)=e^{\theta}=\lambda
\end{align}\]
  </li>
  <li>
    <p><strong>ä¾‹å­ï¼šäºŒé¡¹åˆ†å¸ƒ</strong><br />
å¦‚æœ $Y\overset{\mathrm d}{=}\mathrm{Bin}(m,p)$ï¼Œé‚£ä¹ˆ $\ln f(y\mid m,p)=\text{const}+y\ln \frac{p}{1-p} + m\ln(1-p)$ï¼Œæ‰€ä»¥ $\theta=\ln \frac{p}{1-p}$ï¼Œ$p=\frac{e^{\theta}}{1+e^{\theta}}$ã€‚</p>

    <p>å› æ­¤ï¼Œæˆ‘ä»¬æœ‰ $b(\theta)=-m\ln(1-p)=m\ln(1+e^{\theta})$ï¼Œå¹¶ä¸” $a(\phi)=1$ã€‚</p>

    <p>ç”±ä¸Šé¢çš„ç»“æœå¯å¾—</p>

\[\begin{align}
\mu &amp;= \mathbb{E}(Y)=b'(\theta)=\dfrac{me^{\theta}}{1+e^{\theta}}=mp \\\\
\sigma^2 &amp;= \mathrm{var}(Y)=a(\phi)b''(\theta)=\dfrac{me^{\theta}}{(1+e^{\theta})^2}=mp(1-p)
\end{align}\]
  </li>
</ul>

<h2 id="2-ä¼°è®¡">2. ä¼°è®¡</h2>
<h3 id="21-ä¾‹å­å…·æœ‰å¯¹æ•°è¿æ¥çš„æ³Šæ¾å›å½’æ¨¡å‹">2.1 ä¾‹å­ï¼šå…·æœ‰å¯¹æ•°è¿æ¥çš„æ³Šæ¾å›å½’æ¨¡å‹</h3>

<p>æˆ‘ä»¬æ›´è¯¦ç»†åœ°è€ƒè™‘ä¸€ä¸ªç›¸å½“æ ‡å‡†çš„æ¡ˆä¾‹ â€”â€” <strong>å…·æœ‰å¯¹æ•°è¿æ¥çš„æ³Šæ¾å›å½’æ¨¡å‹ï¼ˆPoisson regression model with log linkï¼‰</strong>ï¼Œè¯¥æ¨¡å‹å¯ä»¥è§†ä¸º GLM çš„ä¸€ä¸ªæ¨¡æ¿ï¼Œå…¶è¿æ¥å‡½æ•°ç­‰äºè‡ªç„¶å‚æ•°ï¼š</p>

<p><strong>ä¾‹å­</strong>ï¼šå…·æœ‰å¯¹æ•°è¿æ¥çš„æ³Šæ¾å›å½’æ¨¡å‹</p>
<ul>
  <li>$Y_i\overset{\mathrm d}{=}\mathrm{Poi}(\lambda_i)$ï¼Œå…¶ä¸­ $i=1,2,\dots,n$ï¼›$Y_i$ ä¹‹é—´å½¼æ­¤ç›¸äº’ç‹¬ç«‹ã€‚</li>
  <li>å‡å€¼å‚æ•° $\lambda$ ä¾èµ–äºåå˜é‡ $\mathbf x_1,\mathbf x_2,\dots,\mathbf x_q$ã€‚</li>
  <li>è‡ªç„¶å‚æ•° $\theta_i=\ln \lambda_i$ã€‚è‡ªç„¶è¿æ¥ $g(\lambda_i)=\ln \lambda_i$ã€‚</li>
  <li>è¿™æä¾›äº†ä¸€ä¸ªå¯¹æ•°çº¿æ€§æ¨¡å‹ \(\eta_i=\ln \lambda_i=\mathbf x_i^{\mathrm{T}}\boldsymbol \beta=\sum_{\ell=1}^{q}x_{i\ell}\beta_{\ell}\)</li>
  <li>å…¶çŸ©é˜µå½¢å¼ä¸ºï¼š$\ln \boldsymbol{\lambda}=\boldsymbol{\eta}=X\boldsymbol{\beta}$ï¼Œå…¶ä¸­ $\boldsymbol{\eta}=(\eta_1,\dots,\eta_n)^{\mathrm{T}},\boldsymbol{\lambda}=(\lambda_1,\dots,\lambda_n)^{\mathrm{T}}$ã€‚</li>
  <li>
    <p>è”åˆå¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼ˆJoint log-likelihood functionï¼‰</p>

\[\begin{align}
\ell (\boldsymbol \beta)=\ln f &amp;= -\sum_{i=1}^{n}\lambda_i+\sum_{i=1}^{n}y_i\ln \lambda_i-\sum_{i=1}^{n}\ln y! \\
&amp;= -\sum_{i=1}^{n}e^{\sum_{\ell=1}^{q}x_{i\ell}\beta_{\ell}}+\sum_{i=1}^{n}y_i\sum_{\ell=1}^{q}x_{i\ell}\beta_{\ell}+\mathrm{const}
\end{align}\]
  </li>
  <li>
    <p>è®°åˆ†å‡½æ•°ï¼ˆscore functionï¼‰</p>

\[\mathbf u(\boldsymbol \beta)=\left(\dfrac{\partial \ln f}{\partial \beta_j}\right)=\left(-\sum_{i=1}^{n}x_{ij}e^{\sum_{\ell=1}^{q}x_{i\ell}\beta_{\ell}}+\sum_{i=1}^{n}x_{ij}y_i\right)=X^{\mathrm{T}}(\mathbf y-\boldsymbol \lambda)\]
  </li>
  <li>
    <p>æµ·æ£®å‡½æ•°ï¼ˆHessian functionï¼‰</p>

\[H(\boldsymbol \beta)=\left(\dfrac{\partial^2 \ln f}{\partial \beta_j \partial \beta_k}\right)=\left(-\sum_{i=1}^{n}x_{ij}x_{ik}e^{\sum_{\ell=1}^{q}x_{i\ell}\beta_{\ell}}\right)=-X^{\mathrm T}\Lambda X\]

    <p>å…¶ä¸­ï¼Œ$\Lambda=\Lambda(\boldsymbol \beta)=\mathrm{diag}(\lambda_1,\lambda_2,\dots,\lambda_n)$ã€‚</p>
  </li>
</ul>

<p>å› æ­¤ï¼Œ</p>

<ul>
  <li>
    <p>è§‚æµ‹ä¿¡æ¯ï¼ˆObserved informationï¼‰</p>

\[J(\boldsymbol \beta)=-H(\boldsymbol \beta)=X^{\mathrm T}\Lambda X\]
  </li>
  <li>
    <p>è´¹é›ªä¿¡æ¯ï¼ˆFisher informationï¼‰</p>

\[I(\boldsymbol \beta)=-\mathbb{E}[H(\boldsymbol \beta)]=X^{\mathrm T}\Lambda X\]
  </li>
  <li>
    <p>è®°åˆ†å‡½æ•°çš„æ–¹å·®ï¼ˆVariance of score functionï¼‰</p>

\[\mathrm{var}(\mathbf u(\boldsymbol \beta))=I(\boldsymbol \beta)=X^{\mathrm T}\Lambda X \overset{\mathrm{denoted}}{=}V(\boldsymbol \beta)\]
  </li>
</ul>

<h3 id="22-è®°åˆ†æ³•method-of-scoring">2.2 è®°åˆ†æ³•ï¼ˆMethod of scoringï¼‰</h3>

<p>$\boldsymbol \beta$ çš„ <strong>æå¤§ä¼¼ç„¶ä¼°è®¡ MLE</strong> $\hat {\boldsymbol \beta}$ å¯ä»¥é€šè¿‡ <strong>ç‰›é¡¿-æ‹‰å¼—æ£®ï¼ˆNewton-Raphsonï¼‰</strong>æˆ–è€… <strong>è´¹é›ªè®°åˆ†æ³•ï¼ˆFisher scoringï¼‰</strong>å¾—åˆ°ã€‚</p>

\[\begin{align}
\hat {\boldsymbol \beta}^{(k+1)} &amp;= \hat {\boldsymbol \beta}^{(k)}+\left[\hat {V}^{(k)} \right]^{-1}\mathbf u(\hat {\boldsymbol \beta}^{(k)}) \\\\
\Longrightarrow \quad \hat {V}^{(k)}\hat {\boldsymbol \beta}^{(k+1)} &amp;= \hat {V}^{(k)}\hat {\boldsymbol \beta}^{(k)}+\mathbf u(\hat {\boldsymbol \beta}^{(k)}) \\\\
\Longrightarrow \quad X^{\mathrm T}\hat{\Lambda}^{(k)}X \hat {\boldsymbol \beta}^{(k+1)} &amp;= X^{\mathrm T}\hat{\Lambda}^{(k)}X \hat {\boldsymbol \beta}^{(k)} + X^{\mathrm T}\hat{\Lambda}^{(k)}\left[(\hat {\Lambda}^{(k)})^{-1} (\mathbf y-\hat {\boldsymbol \lambda}^{(k)}) \right]\\\\
\Longrightarrow \quad X^{\mathrm T}\hat{\Lambda}^{(k)}X \hat {\boldsymbol \beta}^{(k+1)} &amp;= X^{\mathrm T}\hat{\Lambda}^{(k)}\hat{\mathbf z}^{(k)}
\end{align}\]

<p>å…¶ä¸­ï¼Œ</p>

\[\hat{\mathbf z}^{(k)} = X \hat {\boldsymbol \beta}^{(k)}+(\hat {\Lambda}^{(k)})^{-1} (\mathbf y-\hat {\boldsymbol \lambda}^{(k)}) \;,\qquad
\hat {\boldsymbol \lambda}^{(k)} = \boldsymbol \lambda (\hat {\boldsymbol \beta}^{(k)}) \;,\qquad
\hat{\Lambda}^{(k)} = \Lambda (\hat {\boldsymbol \beta}^{(k)})\]

<p>è¿™æœ¬è´¨ä¸Šæ˜¯ <strong>åŠ æƒæœ€å°äºŒä¹˜ç­‰å¼ï¼ˆweighted least squares equationï¼‰</strong>ï¼š</p>

\[X^{\mathrm T}\mathbf W X\hat {\boldsymbol \beta}=X^{\mathrm T}\mathbf {Wy}\]

<p>å› æ­¤ï¼Œè®°åˆ†æ³•ä¸­çš„ <strong>è¿­ä»£æ­¥ï¼ˆiterative stepï¼‰</strong>ç›¸å½“äºåœ¨ $\mathbf x_i$ ä¸Šæ‹Ÿåˆä¸€ä¸ª $\hat z_i^{(k)}$ çš„åŠ æƒå›å½’ï¼Œæƒé‡ä¸º $\hat \lambda_i^{(k)}$ã€‚</p>

<p>æ³¨æ„ï¼Œåœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œ$\hat \lambda_i^{(k)}$ å’Œ $\hat z_i^{(k)}$ çš„å€¼éƒ½éœ€è¦æ›´æ–°ï¼Œå› ä¸ºå®ƒä»¬éƒ½ä¾èµ–äº $\hat{\boldsymbol \beta}^{(k)}$ã€‚</p>

<p>åœ¨å¹¿ä¹‰çº¿æ€§æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬æ€»æ˜¯å¯ä»¥å°†è®°åˆ†æ³•ä¸­çš„è¿­ä»£æ­¥åƒè¿™æ ·è¡¨ç¤ºä¸ºåŠ æƒå›å½’ï¼šè¯¥è¿‡ç¨‹ç§°ä¸º <strong>è¿­ä»£é‡æ–°åŠ æƒæœ€å°äºŒä¹˜æ³•ï¼ˆiteratively re-weighted least squaresï¼ŒIRWLSï¼‰</strong>ã€‚</p>

<p>åœ¨ R è¯­è¨€ä¸­ï¼Œå‡½æ•° <code class="language-plaintext highlighter-rouge">glm()</code> ä¸­å®ç°äº† IRWLS æ–¹æ³•ï¼š</p>

<p>R ä»£ç ï¼š</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="n">glm</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">poisson</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">weights</span><span class="p">,</span><span class="w"> </span><span class="n">subset</span><span class="p">,</span><span class="w"> 
      </span><span class="n">na.action</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">NULL</span><span class="p">,</span><span class="w"> </span><span class="n">etastart</span><span class="p">,</span><span class="w"> </span><span class="n">mustart</span><span class="p">,</span><span class="w"> </span><span class="n">offset</span><span class="p">,</span><span class="w"> 
      </span><span class="n">control</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">...</span><span class="p">),</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"glm.fit"</span><span class="p">,</span><span class="w"> 
      </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">singular.ok</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">contrasts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">NULL</span><span class="p">,</span><span class="w"> </span><span class="n">...</span><span class="p">)</span><span class="w">
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p><a name="eg1"><strong>ä¾‹å­</strong></a>ï¼šæ‹Ÿåˆæ¨¡å‹ $Y_i\overset{\mathrm d}{=}\mathrm{Poi}(\lambda_i)$ï¼Œå…¶ä¸­ $\ln \lambda_i=\beta_0+\beta_1x_i$ï¼Œæ•°æ®å¦‚ä¸‹ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre>x :  -1   -1   0   0   0   0   1   1   1
y :   2    3   6   7   8   9  10  12  15
</pre></td></tr></tbody></table></code></pre></div></div>

<p>R ä»£ç ï¼š</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">-1</span><span class="p">,</span><span class="w"> </span><span class="m">-1</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w">
</span><span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">6</span><span class="p">,</span><span class="w"> </span><span class="m">7</span><span class="p">,</span><span class="w"> </span><span class="m">8</span><span class="p">,</span><span class="w"> </span><span class="m">9</span><span class="p">,</span><span class="w"> </span><span class="m">10</span><span class="p">,</span><span class="w"> </span><span class="m">12</span><span class="p">,</span><span class="w"> </span><span class="m">15</span><span class="p">)</span><span class="w">
</span><span class="n">pr.1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">glm</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">poisson</span><span class="p">)</span><span class="w">
</span><span class="n">summary</span><span class="p">(</span><span class="n">pr.1</span><span class="p">)</span><span class="w">
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>è¾“å‡ºç»“æœï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre></td><td class="rouge-code"><pre>Call:
glm(formula = y ~ x, family = poisson)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.8472  -0.2601  -0.2137   0.5214   0.8788  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   1.8893     0.1421  13.294  &lt; 2e-16 ***
x             0.6698     0.1787   3.748 0.000178 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 18.4206  on 8  degrees of freedom
Residual deviance:  2.9387  on 7  degrees of freedom
AIC: 41.052

Number of Fisher Scoring iterations: 4
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="23-å…·æœ‰è‡ªç„¶è¿æ¥çš„-glm-ä¼°è®¡">2.3 å…·æœ‰è‡ªç„¶è¿æ¥çš„ GLM ä¼°è®¡</h3>
<p>å…·æœ‰è‡ªç„¶è¿æ¥å‡½æ•°çš„å¹¿ä¹‰æŒ‡æ•°æ—åˆ†å¸ƒå’Œä¸Šé¢çš„æ³Šæ¾åˆ†å¸ƒçš„æ¨å¯¼è¿‡ç¨‹ç•¥æœ‰ä¸åŒã€‚</p>

<p>åœ¨å…·æœ‰è‡ªç„¶è¿æ¥çš„å¹¿ä¹‰æƒ…å†µä¸‹ï¼Œ$a(\phi)=\phi \big / w$ï¼Œæˆ‘ä»¬æœ‰</p>

\[\begin{align}
\ell(\boldsymbol \beta) &amp;= \phi^{-1} \sum_{i=1}^{n}w_i[y_i\theta_i-b(\theta_i) ]+\mathrm{const}\\\\
\mathbf u(\boldsymbol \beta) &amp;= \dfrac{\partial \ell}{\partial \boldsymbol \beta}=\left(\phi^{-1}\sum_{i=1}^{n}w_i(y_i-\mu_i)x_{ij} \right)=\phi^{-1}X^{\mathrm T}W(\mathbf y-\boldsymbol \mu)\\\\
J(\boldsymbol \beta) &amp;= -\dfrac{\partial^2 \ell}{\partial \boldsymbol \beta \boldsymbol \beta^{\mathrm T}} = \left(\phi^{-1}\sum_{i=1}^{n}w_i b''(\theta_i)x_{ij}x_{ik} \right)=\phi^{-1}X^{\mathrm T}W\Sigma X = I(\boldsymbol \beta)
\end{align}\]

<p>å…¶ä¸­ï¼Œ</p>

\[\theta_i=\eta_i=\sum_{j=1}^{q}\beta_jx_{ij} \;,\qquad
W=\mathrm{diag}\{w_1,\dots,w_n\} \;,\qquad
\Sigma=\mathrm{diag}\{b''(\theta_1),\dots,b''(\theta_n)\}\]

<p><br /></p>

<p>ä»¤ $V=X^{\mathrm T}W\Sigma X$ï¼Œé‚£ä¹ˆ <strong>MLE</strong> $\hat {\boldsymbol \beta}$ å¯ä»¥é€šè¿‡è®°åˆ†æ³•æ±‚è§£ï¼š</p>

\[\begin{align}
\hat {\boldsymbol \beta}^{(k+1)} &amp;= \hat {\boldsymbol \beta}^{(k)}+\phi\left[\hat {V}^{(k)} \right]^{-1}\mathbf u(\hat {\boldsymbol \beta}^{(k)}) \\\\
\Longrightarrow \quad \hat \phi^{-1}{V}^{(k)}\hat {\boldsymbol \beta}^{(k+1)} &amp;= \phi^{-1}\hat {V}^{(k)}\hat {\boldsymbol \beta}^{(k)}+\mathbf u(\hat {\boldsymbol \beta}^{(k)}) \\\\
\Longrightarrow \quad X^{\mathrm T}W \hat{\Sigma}^{(k)}X \hat {\boldsymbol \beta}^{(k+1)} &amp;= X^{\mathrm T}W \hat{\Sigma}^{(k)}X \hat {\boldsymbol \beta}^{(k)} + X^{\mathrm T}W \hat{\Sigma}^{(k)}\left[(\hat {\Sigma}^{(k)})^{-1} (\mathbf y-\hat {\boldsymbol \mu}^{(k)}) \right]\\\\
\Longrightarrow \quad X^{\mathrm T}W \hat{\Sigma}^{(k)}X \hat {\boldsymbol \beta}^{(k+1)} &amp;= X^{\mathrm T}W \hat{\Sigma}^{(k)}\hat{\mathbf z}^{(k)}
\end{align}\]

<p>å…¶ä¸­ï¼Œ</p>

\[\hat{\mathbf z}^{(k)} = X \hat {\boldsymbol \beta}^{(k)}+(\hat {\Sigma}^{(k)})^{-1} (\mathbf y-\hat {\boldsymbol \mu}^{(k)}) \;,\qquad
\hat {\boldsymbol \mu}^{(k)} = \boldsymbol \mu (\hat {\boldsymbol \beta}^{(k)}) \;,\qquad
\hat{\Sigma}^{(k)} = \Sigma (\hat {\boldsymbol \beta}^{(k)})\]

<p><br /></p>

<p>åœ¨ä¸Šé¢æœ€åä¸¤è¡Œç­‰å¼ä¸­ï¼Œè®°åˆ†æ³•å˜æˆäº† IRWLSï¼š</p>

\[X^{\mathrm T}W \hat{\Sigma}^{(k)}X \hat {\boldsymbol \beta}^{(k+1)} = X^{\mathrm T}W \hat{\Sigma}^{(k)}\hat{\mathbf z}^{(k)}\]

<p>å…¶ä¸­ï¼Œ</p>

\[\hat{\mathbf z}^{(k)} = X \hat {\boldsymbol \beta}^{(k)}+(\hat {\Sigma}^{(k)})^{-1} (\mathbf y-\hat {\boldsymbol \mu}^{(k)}) \;,\qquad
\hat {\boldsymbol \mu}^{(k)} = \boldsymbol \mu (\hat {\boldsymbol \beta}^{(k)}) \;,\qquad
\hat{\Sigma}^{(k)} = \Sigma (\hat {\boldsymbol \beta}^{(k)})\]

<ul>
  <li>IRWLS è¿‡ç¨‹äº§ç”Ÿäº†æ”¶æ•›çš„ MLE $\hat {\boldsymbol \beta}$ã€‚</li>
  <li>
    <p>$\hat {\boldsymbol \beta}$ çš„æ–¹å·®çŸ©é˜µå¯ä»¥è¢«ä¼°è®¡ä¸ºï¼š</p>

\[\widehat {\mathrm{var}}(\hat {\boldsymbol \beta})=\hat \phi \left(X^{\mathrm T}W\Sigma(\hat {\boldsymbol \beta}) X \right)^{-1}\]
  </li>
</ul>

<h2 id="3-æ¨æ–­">3. æ¨æ–­</h2>
<h3 id="31-æ¸è¿‘ä¼¼ç„¶ç†è®º">3.1 æ¸è¿‘ä¼¼ç„¶ç†è®º</h3>
<p>ä¸ºäº†è¿›è¡Œæ¨æ–­ï¼Œæˆ‘ä»¬éœ€è¦äº†è§£æœ‰å…³ç»Ÿè®¡åˆ†å¸ƒçš„ä¸€äº›ä¿¡æ¯ã€‚GLM çš„åŸºç¡€æ˜¯ <strong>æ¸è¿‘ä¼¼ç„¶ç†è®ºï¼ˆasymptotic likelihood theoryï¼‰</strong>ï¼š</p>

\[\mathbf u\overset{\mathrm d}{\sim}N_q(\mathbf 0,I(\boldsymbol \beta))\;,\qquad \mathbf u^{\mathrm T}I^{-1}\mathbf u\overset{\mathrm d}{\sim}\chi^2(q)\]

<p>å…¶ä¸­ï¼Œ$q=\mathrm {dim}(\mathbf x)$ã€‚</p>

<p>å¯¹äº GLMï¼Œ$V$ ä¸­å¹¶ä¸åŒ…å« $\mathbf y$ï¼Œæ‰€ä»¥ $I(\boldsymbol \beta)=\phi^{-1}V$ï¼Œæˆ‘ä»¬æœ‰ï¼š</p>

\[\mathbf u\overset{\mathrm d}{\sim}N_q(\mathbf 0,\phi^{-1}V)\;,\qquad \phi\mathbf u^{\mathrm T}V^{-1}\mathbf u\overset{\mathrm d}{\sim}\chi^2(q)\]

<p>æ›´è¿›ä¸€æ­¥ï¼Œæœ€å¤§ä¼¼ç„¶ä¼°è®¡é‡æ»¡è¶³ï¼š</p>

\[\hat{\boldsymbol \beta} \overset{\mathrm d}{\sim} N_q(\boldsymbol \beta,\phi V^{-1})\;,\qquad \phi^{-1}(\hat{\boldsymbol \beta}-\boldsymbol \beta)^{\mathrm T}V(\hat{\boldsymbol \beta}-\boldsymbol \beta)\overset{\mathrm d}{\sim}\chi^2(q)\]

<p>é€šå¸¸ï¼Œ$V$ ä¸­åŒ…å« $\boldsymbol \beta$ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦åˆ©ç”¨ $V(\hat{\boldsymbol \beta})$ æ¥è®¡ç®— <strong>æ ‡å‡†è¯¯ï¼ˆseï¼‰</strong>ï¼š</p>

\[V=[v_{ij}(\boldsymbol \beta)] \;,\qquad V^{-1}=[v^{ij}(\boldsymbol \beta)]\]

<p><strong>æ ‡å‡†è¯¯ï¼ˆseï¼‰</strong>ä¸ºï¼š$\mathrm{se}(\hat \beta_j)=\sqrt{\phi v^{jj}(\hat{\boldsymbol \beta})}$ $\;\;;\;\;$<strong>è¿‘ä¼¼çš„ $95\%$ ç½®ä¿¡åŒºé—´ï¼ˆCIï¼‰</strong>ä¸ºï¼š$\hat \beta_j\pm 1.96\cdot \mathrm{se}(\hat \beta_j)$</p>

<h3 id="32-æ£€æŸ¥æ¨¡å‹çš„å……åˆ†æ€§">3.2 æ£€æŸ¥æ¨¡å‹çš„å……åˆ†æ€§</h3>
<p>è¯„ä¼°æ¨¡å‹ $M$ çš„ <strong>å……åˆ†æ€§ï¼ˆadequacyï¼‰</strong>ï¼šæ¯”è¾ƒæ¨¡å‹ $M$ çš„ä¼¼ç„¶å’Œ <strong>é¥±å’Œæ¨¡å‹ï¼ˆfull/saturated modelï¼‰</strong>$F$ çš„ä¼¼ç„¶ã€‚å…¶ä¸­ï¼Œé¥±å’Œæ¨¡å‹ $F$ æ˜¯ä¸€ä¸ªå’Œæ¨¡å‹ $M$ å…·æœ‰ç›¸åŒåˆ†å¸ƒå’Œç›¸åŒè¿æ¥å‡½æ•°ï¼Œä½†æ˜¯å‚æ•°æ•°é‡ä¸º $n$ çš„ GLM æ¨¡å‹ã€‚</p>

<p>å¦‚æœæ¨¡å‹ $M$ æ˜¯ä¸€ä¸ªå¥½çš„æ¨¡å‹ï¼Œé‚£ä¹ˆ $L(\boldsymbol \beta_M)$ å°†éå¸¸æ¥è¿‘ $L(\boldsymbol \beta_F)$ï¼šå®ƒèƒ½å¤Ÿè§£é‡Šæ•°æ®ä¸­çš„å¤§éƒ¨åˆ†å˜åŒ–ã€‚</p>

<p>æˆ‘ä»¬å®šä¹‰æ£€éªŒç»Ÿè®¡é‡ï¼š</p>

\[D=2\phi\left[\ln L(\hat{\boldsymbol \beta}_F)-\ln L(\hat{\boldsymbol \beta}_M)\right]\]

<p>è¿™è¢«ç§°ä¸º <strong>å‰©ä½™åå·®ï¼ˆresidual devianceï¼‰</strong>æˆ–è€…ç®€ç§° <strong>åå·®ï¼ˆdevianceï¼‰</strong>ï¼Œå®ƒç±»ä¼¼äºçº¿æ€§æ¨¡å‹ä¸­çš„ <strong>æ®‹å·®å¹³æ–¹å’Œï¼ˆresidual sum of squaresï¼‰</strong>ï¼Œä½†æ˜¯è¿™é‡Œä¸éœ€è¦ä¼°è®¡ $\sigma^2$ï¼Œæ‰€ä»¥ç°åœ¨å¦‚æœ $D$ å¾ˆå¤§çš„è¯ï¼ŒåŸå› å°±æ˜¯æ¨¡å‹æ‹Ÿåˆä¸å¤Ÿå¥½ã€‚</p>

<p>æ£€éªŒåŸºäºä»¥ä¸‹ç»“æœï¼Œå¦‚æœæ¨¡å‹ $M$ æ˜¯æ­£ç¡®çš„ï¼Œé‚£ä¹ˆï¼š</p>

\[\phi^{-1}D\overset{\mathrm d}{\approx}\chi^2(n-q)\]

<p>å¦åˆ™ï¼Œ$D$ å°†è¶‹äºæ›´å¤§ï¼ˆè¿™è¡¨æ˜æ¨¡å‹ $M$ æ‹Ÿåˆä¸å¤Ÿå¥½ï¼‰ã€‚</p>

<p>å› æ­¤ï¼Œå¦‚æœ $D&lt;\chi_{0.95}^{2}(n-q)$ï¼Œé‚£ä¹ˆï¼Œæ¨¡å‹ $M$ æ˜¯å¯ä»¥æ¥å—çš„ã€‚</p>

<p>å›å¿†å‰é¢ <a href="#eg1">æ³Šæ¾åˆ†å¸ƒçš„ä¾‹å­</a>ï¼Œç°åœ¨ï¼Œæˆ‘ä»¬å¯¹ R ä»£ç è¾“å‡ºä¸­å‰©ä½™åå·®çš„æ„ä¹‰æ›´æ¸…æ¥šäº†ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>Residual deviance:  2.9387  on 7  degrees of freedom
</pre></td></tr></tbody></table></code></pre></div></div>

<p>å®ƒè¡¨æ˜ $D=2.9387$ï¼Œå¹¶ä¸” $n-q=7$ï¼ˆå› ä¸º $n=9,\;q=2$ï¼‰ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬æ‹Ÿåˆçš„æ¨¡å‹æ˜¯ç›¸å½“å¯ä»¥æ¥å—çš„ï¼š$\chi_{0.95}^{2}(7)=14.07&gt;D$ã€‚</p>

<h3 id="33-æ¨¡å‹å……åˆ†æ€§æ£€éªŒèƒŒåçš„ç†è®º">3.3 æ¨¡å‹å……åˆ†æ€§æ£€éªŒèƒŒåçš„ç†è®º</h3>

<p>$D$ çš„åˆ†å¸ƒç»“æœæ¥è‡ªæ¸è¿‘ä¼¼ç„¶ç»“æœï¼š</p>

\[\ln L(\boldsymbol \beta)\approx \ln L(\hat {\boldsymbol \beta})+(\boldsymbol \beta-\hat {\boldsymbol \beta})^{\mathrm T}\mathbf u(\hat {\boldsymbol \beta})-\dfrac{1}{2}(\boldsymbol \beta-\hat {\boldsymbol \beta})^{\mathrm T}J(\hat {\boldsymbol \beta})(\boldsymbol \beta-\hat {\boldsymbol \beta})\]

<p>æ³¨æ„ï¼Œå¯¹äº MLE $\hat {\boldsymbol \beta}$ï¼Œ$\mathbf u(\hat {\boldsymbol \beta})=\mathbf 0$ã€‚</p>

<p>ç”±ä¸Šå¼å¯å¾—ï¼š</p>

\[2\left[\ln L(\hat {\boldsymbol \beta})-\ln L(\boldsymbol \beta)\right]\approx (\boldsymbol \beta-\hat {\boldsymbol \beta})^{\mathrm T}J(\hat {\boldsymbol \beta})(\boldsymbol \beta-\hat {\boldsymbol \beta})\overset{\mathrm d}{\sim}\chi^2(q)\]

<p>å…³äºæ¨¡å‹å……åˆ†æ€§çš„æ ‡å‡†æ£€æŸ¥ï¼Œæ›´è¿›ä¸€æ­¥çš„åšæ³•æ˜¯æŸ¥çœ‹ <strong>æ®‹å·®ï¼ˆresidualsï¼‰</strong>ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨å‰é¢ç« èŠ‚ä¸­ä»‹ç»è¿‡çš„è¯Šæ–­å·¥å…·ã€‚</p>

<p>æˆ‘ä»¬å¯ä»¥å°† $D$ è¡¨ç¤ºä¸º $D=\sum_{i=1}^{n}d_i^2$ï¼Œå…¶ä¸­ $d_i^2$ æ˜¯æ¥è‡ªç¬¬ $i$ ä¸ªè§‚æµ‹çš„ä½œç”¨ã€‚é‚£ä¹ˆï¼Œè§‚æµ‹ $i$ çš„ <strong>åå¸¸æ®‹å·®ï¼ˆdeviance residualï¼‰</strong>å®šä¹‰ä¸ºï¼š</p>

\[r_i=\mathrm{sign}(y_i-\hat y_i)|d_i|\;,\quad i=1,\dots,n\]

<h3 id="34-æ¯”è¾ƒåµŒå¥—æ¨¡å‹">3.4 æ¯”è¾ƒåµŒå¥—æ¨¡å‹</h3>

<p>å…³äº <strong>åµŒå¥—æ¨¡å‹ï¼ˆnested modelsï¼‰</strong>æ¯”è¾ƒçš„æ£€éªŒï¼Œå¤„ç†æ–¹æ³•ä¸å¹¿ä¹‰çº¿æ€§æ¨¡å‹ç†è®ºçš„æ£€éªŒåŸºæœ¬ç›¸åŒï¼Œå”¯ä¸€åŒºåˆ«æ˜¯ç°åœ¨ä¸éœ€è¦ä¼°è®¡ $\sigma^2$ã€‚</p>

<p>æ‰€ä»¥ï¼Œæ£€éªŒå¯ä»¥ç›´æ¥åŸºäºç±»ä¼¼äºçº¿æ€§æ¨¡å‹ä¸­æ®‹å·®å¹³æ–¹å’Œçš„å˜åŒ–ï¼ˆå³ï¼ŒGLM ä¸­çš„å‰©ä½™åå·®çš„å˜åŒ–ï¼‰ã€‚</p>

<p>å‡è®¾æ¨¡å‹ $M_0$ åµŒå¥—åœ¨æ¨¡å‹ $M_1$ ä¸­ã€‚å‡è®¾æ¨¡å‹ $M_1$ï¼ˆ$H_1$ å‡è®¾ä¸‹çš„æ¨¡å‹ï¼‰ä¸ºçœŸã€‚ç„¶åï¼Œ</p>

<p>å¦‚æœæ¨¡å‹ $M_0$ ä¹Ÿä¸ºçœŸï¼Œé‚£ä¹ˆï¼š</p>

\[\Delta D=D_0-D_1\overset{\mathrm d}{\approx}\chi^2(q_1-q_0)\]

<p>å¦‚æœæ¨¡å‹ $M_0$ ä¸ä¸ºçœŸï¼Œé‚£ä¹ˆ $\Delta D$ å°†è¶‹è¿‘äºæ›´å¤§ã€‚</p>

<p>å› æ­¤ï¼Œå¦‚æœ $\Delta D&gt;\chi_{0.95}^{2}(q_1-q_0)$ï¼Œé‚£ä¹ˆï¼Œæˆ‘ä»¬æ‹’ç»æ¨¡å‹ $M_0$ã€‚</p>

<p>R ä»£ç ï¼š</p>

<div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">anova</span><span class="p">(</span><span class="n">pr.1</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Chi"</span><span class="p">)</span><span class="w">
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>è¾“å‡ºç»“æœï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre>Analysis of Deviance Table

Model: poisson, link: log

Response: y

Terms added sequentially (first to last)


     Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi)    
NULL                     8    18.4206             
x     1   15.482         7     2.9387 8.33e-05 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
</pre></td></tr></tbody></table></code></pre></div></div>

<p>ç»“æœæ˜¾ç¤ºï¼Œ$D_0=18.4206$ï¼Œ$D_1=2.9387$ï¼Œæ‰€ä»¥</p>

\[\Delta D=D_0-D_1=15.4819\]

<p>å¦‚æœ $M_0$ ä¸ºçœŸï¼Œé‚£ä¹ˆå®ƒå°†ä¼šæ˜¯ $\chi^{2}(1)$ ä¸Šçš„ä¸€ä¸ªè§‚æµ‹ã€‚</p>

<p>ç”±äº $\chi_{0.95}^{2}(1)=3.841&lt;\Delta D$ï¼Œæˆ‘ä»¬æ‹’ç» $M_0$ï¼›å¹¶ä¸”å¾—å‡ºç»“è®º $\beta_1\neq 0$ï¼Œå°±åƒæˆ‘ä»¬å·²ç»ä»è€ƒè™‘ $\hat \beta_1$ å’Œ $\mathrm{se}(\hat \beta_1)$ ä¸­å¾—åˆ°çš„ä¸€æ ·ã€‚</p>

<p><strong>æ³¨æ„</strong>ï¼šæ¯”è¾ƒ $M_0\subset M_1$ å’Œ $M_1$ ç­‰ä»·äºæ£€éªŒçº¿æ€§å‡è®¾ $H_0: \boldsymbol \beta_{M_1-M_0}=\mathbf 0$ã€‚å¯¹äºè¿™ç§æ¯”è¾ƒï¼Œæˆ‘ä»¬å·²ç»å­¦ä¹ äº†ä¸‰ç§æ£€éªŒæ–¹æ³•ï¼š<strong>LR æ£€éªŒ</strong>ã€<strong>Wald æ£€éªŒ</strong> å’Œ <strong>Score æ£€éªŒ</strong>ã€‚è€Œ $\Delta D=D_0-D_1$ æ£€éªŒå¯¹åº”çš„æ˜¯ LR æ£€éªŒã€‚</p>

<p>ä¸‹èŠ‚å†…å®¹ï¼šé€»è¾‘å›å½’æ¨¡å‹åˆ†æåˆ†ç±»æ•°æ®</p>
:ET