I"@<h1 id="lecture-02-统计学习">Lecture 02 统计学习</h1>

<p><strong>参考教材</strong>：</p>

<ul>
  <li><em>Gareth, J., Daniela, W., Trevor, H., &amp; Robert, T. (2013). An intruduction to statistical learning: with applications in R. Spinger.</em></li>
  <li><em>Hastie, T., Tibshirani, R., &amp; Friedman, J. (2009). The elements of statistical learning: data mining, inference, and prediction. Spinger Science &amp; Business Media.</em></li>
</ul>

<h2 id="1-什么是统计学习">1. 什么是统计学习</h2>

<h3 id="11-案例学习">1.1 案例学习</h3>

<h4 id="例子1广告预算与产品销量">例子1：广告预算与产品销量</h4>

<p>我们先来看一个简单的例子，比如受客户委托做统计咨询，为某产品的销量提升提供策略咨询建议。<code class="language-plaintext highlighter-rouge">Advertising</code> (广告) 数据集记录了该产品在 200 个不同市场的销售情况及该产品在每个市场中 3 类广告媒体的预算，这 3 类媒体分别为: <code class="language-plaintext highlighter-rouge">TV</code> (电视)、<code class="language-plaintext highlighter-rouge">radio</code> (广播) 和 <code class="language-plaintext highlighter-rouge">newspaper</code> (报纸)。</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-08-15-WX20200815-221610%402x.png" width="90%" /></p>

<p><span style="font-size:10pt"> <strong><span style="color:steelblue">图 1</span></strong>：<code class="language-plaintext highlighter-rouge">Advertising</code> (广告) 数据集。这个散点图绘制了 200 个不同市场的 <code class="language-plaintext highlighter-rouge">sales</code> (单位: 千) 关于 <code class="language-plaintext highlighter-rouge">TV</code>、<code class="language-plaintext highlighter-rouge">radio</code> 和 <code class="language-plaintext highlighter-rouge">newspager</code> 三种媒体广告预算 (单位: 千美元) 的函数。每个散点图我们都给出了 <code class="language-plaintext highlighter-rouge">sales</code> 这个变量通过普通最小二乘法的拟合线，拟合的这个结果将在下节课详解。换句话说，在每个图中的蓝线代表一个简单的模型，这条线可以用来预测 <code class="language-plaintext highlighter-rouge">TV</code>、<code class="language-plaintext highlighter-rouge">radio</code> 和 <code class="language-plaintext highlighter-rouge">newspager</code>  的 <code class="language-plaintext highlighter-rouge">sales</code>。</span></p>

<p>一般情况，假设观察到一个定量的响应变量 $Y$，以及 $p$ 个不同的预测变量 $X_1,X_2,\dots,X_p$。假设 $Y$ 和 $X=(X_1,X_2,\dots,X_p)$ 之间存在某种关系，可以用下面的一般形式表示:</p>

<script type="math/tex; mode=display">Y=f(X)+\epsilon</script>

<p>这里，$f$ 是某个关于 $X_1,X_2,\dots,X_p$ 的固定的未知函数，并且 $\epsilon$ 是一个独立于 $X$ 且均值为零的随机 <strong>误差项 (error term)</strong>。这种形式下，$f$ 代表了由 $X$ 提供的关于 $Y$ 的 <strong>系统 (systematic)</strong> 信息。</p>

<h4 id="例子2个人收入与受教育年限">例子2：个人收入与受教育年限</h4>

<p>我们再来看另一个例子，图 2 表示了 <code class="language-plaintext highlighter-rouge">Income</code> (收入) 数据集中 30 个人的 <code class="language-plaintext highlighter-rouge">Income</code> (收入) 与各自 <code class="language-plaintext highlighter-rouge">years of education</code> (受教育年限) 的关系。</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-08-15-WX20200815-232925%402x.png" width="80%" /></p>

<p><span style="font-size:10pt"> <strong><span style="color:steelblue">图 2</span></strong>：<code class="language-plaintext highlighter-rouge">Income</code> 数据集。<strong>左图</strong>：图中的点为 <code class="language-plaintext highlighter-rouge">income</code> 观测值 (单位: 千美元) 和 30 个人 的 <code class="language-plaintext highlighter-rouge">years of education</code>。<strong>右图</strong>：曲线代表真实的 <code class="language-plaintext highlighter-rouge">income</code> 和 <code class="language-plaintext highlighter-rouge">years of education</code> 的关系，一般情况下该线是未知的 (但这里是己知的，因为收入数据是模拟的)。竖线表示与每个观测值有关的误差。若观测点落在曲线上方，则误差为正，若观测点落在曲线的下方，则误差为负。总体来看，误差的均值接近于 0。</span></p>

<p>一般而言，估计函数 $f$ 会涉及多个输入变量，如图 3 所示，作 <code class="language-plaintext highlighter-rouge">income</code> 对 <code class="language-plaintext highlighter-rouge">years of education</code> 和 <code class="language-plaintext highlighter-rouge">seniority</code> (专业资质) 的函数 $f$。这里 $f$ 是一个基于观测值估计的二维曲面。</p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-08-16-WX20200816-142600%402x.png" width="60%" /></p>

<p><span style="font-size:10pt"> <strong><span style="color:steelblue">图 3</span></strong>：该图表示的是 <code class="language-plaintext highlighter-rouge">Income</code> 数据集中 <code class="language-plaintext highlighter-rouge">income</code> 关于 <code class="language-plaintext highlighter-rouge">years of education</code> 和 <code class="language-plaintext highlighter-rouge">seniority</code> 的函数，曲面代表实际的 <code class="language-plaintext highlighter-rouge">income</code> 与 <code class="language-plaintext highlighter-rouge">years of education</code> 和 <code class="language-plaintext highlighter-rouge">seniority</code> 的关系，它是己知的，这是因为这个数据是模拟得到的。其中，图中的点表示 30 个人的模拟观测值。</span></p>

<p>实际上，<strong>统计学习是关于估计 $f$ 的一系列方法</strong>。在节课中我们将集中介绍几个在估计 $f$ 时所需要的关键理论概念，这些概念将用于估计 $f$，同时这些概念也用于对所得估计进行评价。</p>

<h3 id="12-为什么需要估计-f">1.2 为什么需要估计 $f$</h3>

<p>估计 $f$ 的主要原因有两个：<strong>预测 (prediction)</strong> 和 <strong>推断 (inference)</strong>。</p>

<h4 id="预测">预测</h4>

<p>许多情形下，输入集 $X$ 是现成的，但输出 $Y$ 是不易获得的。这时，由于误差项的均值是 $0$ ，那么可通过下式预测 $Y$：</p>

<script type="math/tex; mode=display">\hat Y=\hat f(X)</script>

<p>这里 $\hat f$ 表示 $f$ 的估计，$\hat Y$ 表示 $Y$ 的预测值。在这种设定下，$\hat f$ 通常被视为一个 <strong>黑箱 (black box)</strong>，这表示一般意义下，如果该黑箱能提供准确的关于 $Y$ 的预测，则并不十分追求 $\hat f$ 的确切形式。</p>

<p>$\hat Y$ 作为响应变量 $Y$ 的预测，其准确性依赖于两个量：<strong>可减小误差 (reducible error)</strong> 和 <strong>不可减小误差 (irreducible error)</strong>。通常，$\hat f$ 并不是 $f$ 的一个完美估计，这种不准确性也会引入一些误差，但这类误差是 <strong>可减小的</strong>，因为我们实际上有能力提高 $f$ 的准确性，<strong>只要选择更合适的统计学习技术去估计 $f$ 就可能降低这种误差</strong>。然而，即使有可能构造出一个 $f$ 的完美估计，使得我们的估计响应取得 $\hat Y=f(X)$ 的形式，我们的预测中仍然会存在一些误差。这是因为 $Y$ 还是一个关于 $\epsilon$ 的函数，并且按照定义，$\epsilon$ 无法通过 $X$ 来预测。因此，与 $\epsilon$ 相关的可变性同样影响着我们预测的准确性。这部分误差就被称为 <strong>不可减小</strong> 误差，因为 <strong>无论我们对 $f$ 估计得多么好，我们都无法减小由 $\epsilon$ 引入的误差</strong>。</p>

<p>考虑一个给定的估计 $\hat f$ 和一组预测变量 $X$，将产生预测 $\hat Y=\hat f(X)$。假设 $\hat f$ 和 $X$ 是固定的，于是很容易证明：</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
E(Y-\hat Y)^2 &= E[\,f(X)+\epsilon -\hat f(X)]^2 \\
&= \underbrace{[\,f(X)-\hat f(X)]^2}_{可减小误差} + \underbrace{\mathrm{Var}(\epsilon)}_{不可减小误差}
\end{align} %]]></script>

<p>其中，$E(Y-\hat Y)^2$ 代表了 $Y$ 的预测值和实际值之差的平方的均值，或者 <strong>期望值</strong>，而 $\mathrm{Var}(\epsilon)$ 代表了和误差项 $\epsilon$ 相关的 <strong>方差</strong>。</p>

<p><strong>为什么不可减小误差会大于零呢？</strong></p>

<ul>
  <li>首先，$\epsilon$ 可能包含了某些 <strong>未测量变量 (unmeasured variables)</strong>，它们对于预测 $Y$ 有用：由于没有测量它们，所以 $f$ 在预测时无法使用这些变量。</li>
  <li>其次，$\epsilon$ 可能还包含了一些 <strong>不可测量的差异 (unmeasurable variation)</strong>。例如，某天某个特定患者对于某种药物的不良反应风险可能会有所不同，具体取决于药物本身在制造过程中产生的差异，或者患者当天的情绪状态等。</li>
</ul>

<h4 id="推断">推断</h4>

<p>很多情况下，我们对当 $X_1,X_2,\dots,X_p$ 变化时对 $Y$ 产生怎样的影响比较感兴趣。在这种情形下，我们想要估计 $f$，但我们的目的并不一定是为了预测 $Y$，而是希望理解 $X$ 和 $Y$ 之间的关系，更确切地，是去理解 $Y$ 作为一个关于 $X_1,X_2,\dots,X_p$ 的函数是如何变化的。这种情况下，$\hat f$ 不能再被视为黑箱，因为我们需要知道它的具体形式。在这种设定下，我们可能对以下问题感兴趣：</p>

<ul>
  <li>
    <p><strong>哪些预测变量与响应变量相关？</strong> 通常情况下用于预测的变量中只有一小部分与 $Y$ 充分相关，从一大组可能的变量中根据应用的需要识别一些重要的预测变量是极其有必要的。</p>
  </li>
  <li>
    <p><strong>响应变量与每个预测变量之间的关系是什么？</strong> 一些预测变量与 $Y$ <strong>正相关</strong>，这意味着，当增加相应的预测变量的值时，$Y$ 的值也会增加。而另一些预测变量则与 $Y$ 呈 <strong>负相关</strong>。取决于 $f$ 的复杂性，响应变量与某个给定的预测变量之间的关系也可能依赖于其他预测变量的值。</p>
  </li>
  <li>
    <p><strong>$Y$ 与每个预测变量的关系是否能用一个线性方程概括，或者需要更复杂的形式？</strong> 过去，大多数估计 $f$ 的方法都采用线性形式。在一些情况下，这种假设是合理的甚至是比较理想的方式。但更一般的情况下，<strong>真正的关系</strong> 可能更为复杂，此时，线性模型可能无法提供一种准确的表达。</p>
  </li>
</ul>

<p>如果我们的问题是推断，我们无法使用神经网络或者深度学习。因为在神经网络和深度学习中，我们的案例是复杂的网络，这种情况下，我们无法理解问题背后的发生的事情，我们能够理解的只有结果。因此，<strong>问题的类型决定了我们需要使用的工具</strong>，所以，在数据科学中，我们首先需要弄清 <strong>决策者的意图是什么：预测、推断，或者两者皆有</strong>。</p>

<h3 id="13-如何估计-f">1.3 如何估计 $f$</h3>

<p>假设己观测到一组 $n$ 个不同的点。例如在图 2 中，我们观测到 $n=30$ 个数据点。这些观测点称为 <strong>训练数据</strong>，因为我们要用这些观测点去训练或引导我们的方法怎样估计 $f$。令 $x_{ij}$ 表示观测点 $i$ 的第 $j$ 个预测变量或输入的值，其中 $i = 1,2,\dots,n$ 并且 $j =1,2,\dots,p$。相应地，令 $y_i$ 表示第 $i$ 观测点的响应变量值。训练数据记为 $\{(x_1,y_1),(x_2,y_2),\dots,(x_n,y_n)\}$，其中 $x_i=(x_{i1},x_{i2},\dots,x_{ip})^{\mathrm T}$。</p>

<p>我们的目标是对训练数据应用统计学习方法来估计未知函数 $f$。换而言之，我们希望找到一个函数 $\hat f$，使得对任意观测点 $(X,Y)$ 都有 $Y=\hat f(X)$。一般而言，该任务涉及的大多数统计学习方法都可分为两大类：<strong>参数方法</strong> 和 <strong>非参数方法</strong>。</p>

<h4 id="参数方法">参数方法</h4>

<p>参数方法是一种基于模型估计的两阶段方法。</p>

<ol>
  <li>
    <p>首先，我们对函数 $f$ 的形式或形状给出一个假设。例如，一个常用假设是 $f$ 关于 $X$ 是线性的：</p>

    <script type="math/tex; mode=display">f(X)=\beta_0+\beta_1 X_1 +\beta_2 X_2 +\cdots + \beta_p X_p</script>

    <p>这是一个 <strong>线性模型 (linear model)</strong>，我们将在下节课展开讨论。一旦假设 $f$ 是线性的，估计 $f$ 的问题将被大大简化：我们不必去估计一个完全任意的 $p$ 维函数 $f(X)$，而只需估计 $p+1$ 个系数 $\beta_0,\beta_1,\dots,\beta_p$。</p>
  </li>
  <li>
    <p>在选定一个模型后，我们需要用训练数据集去 <strong>拟合</strong> 或 <strong>训练</strong> 模型。在上面的线性模型中，我们需要估计参数 $\beta_0,\beta_1,\dots,\beta_p$。这就是说，我们希望找到这些参数的值使得：</p>

    <script type="math/tex; mode=display">Y\approx \beta_0+\beta_1 X_1 +\beta_2 X_2 +\cdots + \beta_p X_p</script>

    <p>对于该模型，最常用的拟合方法称是 <strong>普通最小二乘法 (ordinary least squares, OLS)</strong>，具体细节将在下节课中讨论。然而，最小二乘法只是众多用于拟合线性模型的方法中的一种，在后面的课程中，我们会讨论一些其他用来估计该模型参数的方法。</p>
  </li>
</ol>

<p>基于模型的方法统称为 <strong>参数法 (parametric)</strong>；参数法把估计 $f$ 的问题简化为估计一组参数。对 $f$ 假设一个具体的参数形式将简化对 $f$ 的估计，因为估计参数是更为容易的，比如线性模型只需要估计 $\beta_0,\beta_1,\dots,\beta_p$，而不需要拟合一个任意函数 $f$。<strong>参数方法的缺陷是选定的模型与真实的 $f$ 在形式上并非是一致的</strong>。假如我们选择的模型与真实的 $f$ 差距太大，我们的估计效果将很差。此类问题的一种解决思路是尝试通过选择 <strong>易扩展 (flexible) 模型</strong> 拟合很多不同形式的函数 $f$。但一般来说，拟合易扩展程度更强的模型需要更多的参数估计。拟合复杂的模型会导致 <strong>过拟合 (overfitting)</strong>，即模型拟合了错误或 <strong>噪声 (nosie)</strong>。</p>

<p>图 4 给出了一个参数模型的例子，其中数据来自于图 3 中的 <code class="language-plaintext highlighter-rouge">Income</code> 数据集。一个线性拟合如下所示:</p>

<script type="math/tex; mode=display">\texttt {income} \approx \beta_0+\beta_1 \times \texttt{education}+\beta_2 \times \texttt{seniority}</script>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-08-17-WX20200817-135823%402x.png" width="60%" /></p>

<p><span style="font-size:10pt"> <strong><span style="color:steelblue">图 4</span></strong>：对图 3 中的 <code class="language-plaintext highlighter-rouge">Income</code> 数据进行最小二乘线性模型拟合。图中观测值用红色点标识，平面表示对数据进行最小二乘拟合图形。</span></p>

<p>由于假设响应变量与两个预测变量之间的关系是线性的，整个拟合问题就简化为用最小二乘线性回归去估计参数 $\beta_0,\beta_1$ 和 $\beta_2$。对比图 3 和图 4，我们发现图 4 中 的线性拟合不够精确：真实的 $f$ 有一定的曲率，线性拟合无法抓住这些特征。然而，线性拟合看上去仍然是一个比较合理的估计，因为它捕获了 <code class="language-plaintext highlighter-rouge">year of education</code> 和 <code class="language-plaintext highlighter-rouge">income</code> 之间的正相关关系，以及 <code class="language-plaintext highlighter-rouge">seniority</code> 和 <code class="language-plaintext highlighter-rouge">income</code> 之间微弱的正相关关系。可能是由于观测的数据量太少，但就模型而言，它已经竭尽所能了。</p>

<p>下节内容：统计学习</p>
:ET