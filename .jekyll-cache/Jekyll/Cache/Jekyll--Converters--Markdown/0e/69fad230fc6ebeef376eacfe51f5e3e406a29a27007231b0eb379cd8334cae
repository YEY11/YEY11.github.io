I"<h1 id="lecture-10-bagging-和随机森林">Lecture 10 Bagging 和随机森林</h1>

<p><strong>参考教材</strong>：</p>

<ul>
  <li><em>Hardle, W. and Simar, L (2015). Applied multivariate statistical analysis, 4th edition.</em></li>
  <li><em>Hastie, T. Tibshirani, R. and Friedman, J. (2009). The elements of statistical learning, 2nd edition</em></li>
</ul>

<h2 id="1-bagging-分类树">1. Bagging 分类树</h2>

<p>树模型具有 <strong>高方差</strong>。相似的样本可能会生成截然不同的树，尤其是在各个分量 ($X_j$) 相关性很高的情况下。这会导致预测结果不稳定。</p>

<p>从更高的层面来看，这是由于在顶部划分sh中产生的错误会向下传播到其下方的所有拆分。</p>

<p>*套袋是减少差异的一种方法：我们不生产一棵树，而是根据我们的数据生产许多（例如B）深树。 然后，我们以一种或另一种方式聚合（或“包装”）这些B树。</p>

<p>*深树的偏差较小，但差异较大。 汇总它们可以克服方差问题。 （直觉：随机变量的平均值通常具有较小的方差，聚集具有相似的效果）。</p>

<p><span style="font-size:10pt"> <span style="color:steelblue;font-weight:bold">图 2</span>：垃圾邮件例子的剪枝树。分裂变量在分支上显示为蓝色，分类则显示在每个结点上。终端结点下面的数字表示测试数据上的误分类率。</span></p>

<p>下节内容：Boosting 和随机森林</p>
:ET