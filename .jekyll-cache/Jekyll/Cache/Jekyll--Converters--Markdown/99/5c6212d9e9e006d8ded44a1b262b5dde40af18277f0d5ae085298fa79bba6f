I"ед<h1 id="lecture-15-Ф█÷Е╓╠Е┤╫Ф∙╟-Д╦─">Lecture 15 Ф█÷Е╓╠Е┤╫Ф∙╟ (Д╦─)</h1>

<p>Е°╗Е┴█Е┤═Х┼┌Х╞╬Д╦╜О╪▄Ф┬▒Д╩╛Е╜╕Д╧═Д╨├Ф╗║Е·▀Ф╗║Е²≈Д╦╜Г └Д╦─Д╨⌡Г÷╔Х╞├О╪▄Е▄┘Ф▀╛Е╕┌Д╫∙Ф·└Е╩╨Ф╗║Е·▀Д╩╔Е▐┼Ф─▌Ф═╥Х©⌡Х║▄Ф╗║Е·▀Е┬²Е╖▀Е▄√Ц─┌Ф°╛Х┼┌Х╞╬Ф┬▒Д╩╛Е╟├Е╪─Е╖▀Е╜╕Д╧═Ф█÷Е╓╠Е┤╫Ф∙╟Ф╗║Е²≈Ц─┌</p>

<h2 id="1-Ф█÷Е╓╠Е┤╫Ф∙╟Г └Ф╕┌Е©╣">1. Ф█÷Е╓╠Е┤╫Ф∙╟Г └Ф╕┌Е©╣</h2>

<p><strong>Ф█÷Е╓╠Е┤╫Ф∙╟ (Loss Function)</strong>О╪ Х║║И┤▐Ф╗║Е·▀Х╬⌠Е┤╨Д╦▌Г°÷Е╝·Ф═┤Г╜╬Д╧▀И≈╢Г └Е╥╝Е╪┌Ц─┌</p>

<p>Д╦▀И²╒Ф≤╞Д╦─Д╦╙Д╦─Е┘┐Г╨©Ф─╖Е⌡·Е╫▓Г └Ф▀÷Е░┬Х©┤Г╗▀Г╓╨Ф└▐Е⌡╬О╪ </p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-12-20-WX20201220-200705%402x.png" width="60%" /></p>

<p>Е⌡╬Д╦╜Г └Г╩©Х┴╡Ф√╧Е²≈Д╩ёХ║╗Х╝╜Г╩┐Ф═╥Ф°╛Г┌╧ $(x_i, y_i)$О╪▄Х⌠²Х┴╡Г⌡╢Г╨©Д╩ёХ║╗Х╝╜Г╩┐Е╬≈Е┬╟Г └Ф╗║Е·▀ $\hat y = w_0 + w_1 x$О╪▄Е┘╤Д╦╜О╪▄$w_0$ Д╩ёХ║╗Ф┬╙Х╥²О╪▄$w_1 = \Delta y / \Delta x$ Д╩ёХ║╗Ф√°Г▌┤Ц─┌Е▐╞Д╩╔Г°▀Е┬╟О╪▄Ф╗║Е·▀Е╧╤Ф╡║Ф°┴Е╝▄Г╬▌Е°╟Ф▀÷Е░┬Ф╞▐Д╦─Д╦╙Ф∙╟Ф█╝Г┌╧О╪▄Ф┴─Д╩╔Ф∙╟Ф█╝Г┌╧Е▓▄Ф╗║Е·▀Д╧▀И≈╢Е╜≤Е°╗Д╦─Д╦╙ <strong>Ф█÷Е╓╠ (Loss)</strong>О╪▄Х©≥И┤▄Ф┬▒Д╩╛И┤┤Г■╗Е·┌Г⌡╢Ф√╧Е░▒Д╦┼Ф╗║Е·▀Х╬⌠Е┤╨Д╦▌Г°÷Е╝·Ф∙╟Ф█╝Г┌╧Д╧▀Е╥╝Г └Г╩²Е╞╧Е─╪ $|\hat y -y|$ Д╫°Д╦╨Ф█÷Е╓╠Е┤╫Ф∙╟Г └Е╨╕И┤▐Ц─┌</p>

<p>Е▐╕Е╓√О╪▄Е╫⌠Ф┬▒Д╩╛Х╟┬Е┬╟Ф█÷Е╓╠Е┤╫Ф∙╟Ф≈╤О╪▄Г╩▐Е╦╦Д╪ Ф╤┴Е▐┼Е┬╟Д╩╔Д╦▀Д╦┴Д╦╙Ф╕┌Е©╣О╪ </p>

<ul>
  <li>
    <p><strong>Ф█÷Е╓╠Е┤╫Ф∙╟ (Loss Function)</strong>О╪ Х╝║Г╝≈Е█∙Д╦╙Ф═╥Ф°╛Г └Е╥╝Е╪┌Ц─┌</p>

\[\mathrm{Loss} = f(\hat y, y)\]
  </li>
  <li>
    <p><strong>Д╩ёД╩╥Е┤╫Ф∙╟ (Cost Function)</strong>О╪ Х╝║Г╝≈Ф∙╢Д╦╙Х╝╜Г╩┐И⌡├ $\mathrm{Loss}$ Г └Е╧ЁЕ²┤Е─╪Ц─┌</p>

\[\mathrm{Cost} = \dfrac{1}{n}\sum_{i=1}^{n} f(\hat y_i, y_i)\]
  </li>
  <li>
    <p><strong>Г⌡╝Ф═┤Е┤╫Ф∙╟ (Objective Function)</strong>О╪ Ф°─Г╩┬И°─Х╕│Д╪≤Е▄√Г └Г⌡╝Ф═┤О╪▄И─ Е╦╦Е▄┘Е░╚Д╩ёД╩╥Е┤╫Ф∙╟Е▓▄Ф╜ёЕ┬≥И║╧Ц─┌</p>

\[\mathrm{Obj} = \mathrm{Cost} + \mathrm{Regularization}\]
  </li>
</ul>

<p>ФЁ╗Ф└▐О╪▄Д╩ёД╩╥Е┤╫Ф∙╟Е╧╤Д╦█Ф≤╞Х╤┼Е╟▐Х╤┼Е╔╫О╪▄Е⌡═Д╦╨Е╜≤Е°╗Х©┤Ф▀÷Е░┬Г └Иё▌И≥╘Ц─┌Ф┴─Д╩╔Ф┬▒Д╩╛И°─Х╕│Е┼═Д╦┼Д╦─Д╨⌡Г╨╕Ф²÷ (Е█ЁФ╜ёЕ┬≥И║╧) Ф²╔И≤╡Ф╜╒Ф╗║Е·▀Е▐≤Е╬≈Х©┤Д╨▌Е╓█Ф²┌Х─▄Е╞╪Х┤╢Х©┤Ф▀÷Е░┬О╪▄Е╦╦Г■╗Г └Ф°┴ L1 Е▓▄ L2 Ф╜ёЕ┬≥И║╧Ц─┌Е⌡═Ф╜╓О╪▄Д╩ёД╩╥Е┤╫Ф∙╟Е▓▄Ф╜ёЕ┬≥И║╧Ф°─Г╩┬Ф·└Ф┬░Д╨├Ф┬▒Д╩╛Г └Г⌡╝Ф═┤Е┤╫Ф∙╟Ц─┌</p>

<p>Д╦▀И²╒Ф┬▒Д╩╛Ф²╔Г°▀Д╦─Д╦▀ PyTorch Д╦╜Г └ <code class="language-plaintext highlighter-rouge">_Loss</code> Г╠╩О╪ </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">_Loss</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="nb">reduce</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'mean'</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_Loss</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">size_average</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">or</span> <span class="nb">reduce</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">reduction</span> <span class="o">=</span> <span class="n">_Reduction</span><span class="p">.</span><span class="n">legacy_get_string</span><span class="p">(</span><span class="n">size_average</span><span class="p">,</span> <span class="nb">reduce</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">reduction</span> <span class="o">=</span> <span class="n">reduction</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Е▐╞Д╩╔Г°▀Е┬╟О╪▄<code class="language-plaintext highlighter-rouge">_Loss</code> Ф≤╞Г╩╖Ф┴©Д╨▌ <code class="language-plaintext highlighter-rouge">Module</code> Г╠╩Г └О╪▄Ф┴─Д╩╔Д╩▌Ф÷░Г╖█Г╗▀Е╨╕Д╦┼Ф┬▒Д╩╛Е▐╞Д╩╔Е╟├ <code class="language-plaintext highlighter-rouge">_Loss</code> Д╧÷Х╖├Д╦╨Д╦─Д╦╙Г╫▒Г╩°Е╠┌Ц─┌Е╝┐Г └Е┬²Е╖▀Е▄√Е┤╫Ф∙╟Д╦╜Д╦╩Х╕│Ф°┴ 3 Д╦╙Е▐┌Ф∙╟О╪▄Е┘╤Д╦╜ <code class="language-plaintext highlighter-rouge">size_average</code> Е▓▄ <code class="language-plaintext highlighter-rouge">reduce</code> Х©≥Д╦╓Д╦╙Е▐┌Ф∙╟Е█ЁЕ╟├Е°╗Е░▌Г╩╜Г┴┬Ф°╛Д╦╜Х╒╚Х┬█Е╪┐О╪▄Е⌡═Д╦╨ <code class="language-plaintext highlighter-rouge">reduction</code> Е▐┌Ф∙╟Е╥╡Г╩▐Е▐╞Д╩╔Е╝·Г▌╟Е┴█Д╦╓Х─┘Г └Е┼÷Х┐╫Ц─┌</p>

<h2 id="2-Д╨╓Е▐┴Г├╣Ф█÷Е╓╠Е┤╫Ф∙╟">2. Д╨╓Е▐┴Г├╣Ф█÷Е╓╠Е┤╫Ф∙╟</h2>

<p>Е°╗Е┬├Г╠╩Д╩╩Е┼║Д╦╜О╪▄Ф┬▒Д╩╛Г╩▐Е╦╦И┤┤Г■╗Г └Ф≤╞Д╨╓Е▐┴Г├╣Ф█÷Е╓╠Е┤╫Ф∙╟Ц─┌Е°╗Е┬├Г╠╩Д╩╩Е┼║Д╦╜Ф┬▒Д╩╛Е╦╦Е╦╦И°─Х╕│Х╝║Г╝≈Д╦█Е░▄Г╠╩Е┬╚Г └Ф╕┌Г▌┤Е─╪О╪▄Ф┴─Д╩╔Д╨╓Е▐┴Г├╣Е▐╞Д╩╔Г■╗Ф²╔Х║║И┤▐Д╦╓Д╦╙Ф╕┌Г▌┤Е┬├Е╦┐Д╧▀И≈╢Г └Е╥╝Е╪┌О╪▄Д╨╓Е▐┴Г├╣Е─╪Х╤┼Д╫▌Х╞╢Ф≤▌Д╦╓Д╦╙Ф╕┌Г▌┤Е┬├Е╦┐Х╤┼Ф▌╔Х©▒Ц─┌</p>

<p>И┌ёД╧┬Д╦╨Д╩─Д╧┬Д╨╓Е▐┴Г├╣Е─╪Х╤┼Д╫▌О╪▄Д╦╓Д╦╙Ф╕┌Г▌┤Е┬├Е╦┐Х╤┼Ф▌╔Х©▒Е▒╒О╪÷Х©≥И°─Х╕│Д╩▌Е╝┐Д╦▌Д©║Ф│╞Г├╣Е▓▄Г⌡╦Е╞╧Г├╣Д╧▀И≈╢Г └Е┘ЁГЁ╩Х╞╢Х╣╥О╪ </p>

<p><span><center>Д╨╓Е▐┴Г├╣ $=$ Д©║Ф│╞Г├╣ $+$ Г⌡╦Е╞╧Г├╣</center></span></p>

<p>Ф┬▒Д╩╛Е┘┬Ф²╔Г°▀Ф°─Е÷╨Ф°╛Г └ <strong>Г├╣ (Entropy)</strong> Г └Ф╕┌Е©╣О╪ Г├╣Е┤├Г║╝Ф²╔Х╞╢Е╨■Х╞╔Е▐╚Е│  <strong>Д©║Ф│╞Г├╣ (Information Entropy)</strong>О╪▄Е╝┐Ф≤╞Г■╠Д©║Ф│╞Х╝╨Д╧▀Г┬╤И╕≥Е├°Д╩▌Г┐╜Е┼⌡Е╜╕Д╦╜Е─÷И┴╢Х©┤Ф²╔Г └Д╦─Д╦╙Ф╕┌Е©╣О╪▄Г■╗Д╨▌Ф▐▐Х©╟Ф÷░Д╦╙Д╨▀Д╩╤Г └Д╦█Г║╝Е╝ Ф─╖О╪ Ф÷░Д╦╙Д╨▀Д╩╤Д╦█Г║╝Е╝ Ф─╖Х╤┼И╚≤О╪▄Е╝┐Г └Г├╣Е╟╠Х╤┼Е╓╖Ц─┌Д╬▀Е╕┌О╪ Б─°Ф≤▌Е╓╘Д╦▀И⌡╗Б─² Х©≥Д╦─Д╨▀Д╩╤Х╕│Ф╞■ Б─°Ф≤▌Е╓╘Е╓╙И≤ЁД╪ Е█┤Х╣╥Б─² Х©≥Д╦─Д╨▀Д╩╤Г └Г├╣Е╓╖Е╬≈Е╓ О╪▄Е⌡═Д╦╨Е┴█Х─┘Г └Д╦█Г║╝Е╝ Ф─╖Х╬┐И╚≤Ц─┌Х©≥И┤▄Ф┬▒Д╩╛И°─Х╕│Е╪∙Е┘╔ <strong>Х┤╙Д©║Ф│╞</strong> Г └Ф╕┌Е©╣Ц─┌</p>

<ul>
  <li>
    <p><strong>Х┤╙Д©║Ф│╞ (Self-information)</strong>О╪ Г■╗Д╨▌Х║║И┤▐Е█∙Д╦╙Д╨▀Д╩╤Г └Д╦█Г║╝Е╝ Ф─╖Ц─┌</p>

\[I(X) = -\log [P(X)]\]

    <p>Е┘╤Д╦╜О╪▄$P(X)$ Д╦╨Д╨▀Д╩╤ $X$ Г └Ф╕┌Г▌┤Ц─┌</p>
  </li>
  <li>
    <p><strong>Г├╣ (Entropy)</strong>О╪ Х┤╙Д©║Ф│╞Г └Ф°÷Ф°⌡О╪▄Г■╗Д╨▌Ф▐▐Х©╟Ф∙╢Д╦╙Ф╕┌Г▌┤Е┬├Е╦┐Г └Д╦█Г║╝Е╝ Ф─╖Ц─┌Д╨▀Д╩╤Г └Д╦█Г║╝Е╝ Ф─╖Х╤┼И╚≤О╪▄Е╝┐Г └Г├╣Е╟╠Х╤┼Е╓╖Ц─┌</p>

\[H(P) = \mathrm{E}_{X\sim P}[I(X)] = \sum_{i=1}^{n}P(x_i)\log P(x_i)\]
  </li>
</ul>

<p>Д╦╨Д╨├Ф⌡╢Е╔╫Е°╟Г░├Х╖ёГ├╣Д╦▌Д╨▀Д╩╤Д╦█Г║╝Е╝ Ф─╖Г └Е┘ЁГЁ╩О╪▄Ф┬▒Д╩╛Ф²╔Г°▀Д╦─Д╦╙Г╓╨Ф└▐Е⌡╬О╪ </p>

<p><img src="http://andy-blog.oss-cn-beijing.aliyuncs.com/blog/2020-12-20-entropy.png" width="60%" /></p>

<p>Д╦┼И²╒Ф≤╞Д╪╞Е┼╙Е┬╘Е┬├Е╦┐ (Д╦╓Г┌╧Е┬├Е╦┐) Г └Д©║Ф│╞Г├╣О╪▄Е▐╞Д╩╔Г°▀Е┬╟О╪▄Е╫⌠Д╨▀Д╩╤Ф╕┌Г▌┤Д╦╨ $0.5$ Ф≈╤О╪▄Е╝┐Г └Д©║Ф│╞Г├╣Ф°─Е╓╖О╪▄Е╓╖Г╨╕Е°╗ $0.69$ И≥└Х©▒О╪▄Е█ЁФ╜╓Ф≈╤Х╞╔Д╨▀Д╩╤Г └Д╦█Г║╝Е╝ Ф─╖Ф≤╞Ф°─Е╓╖Г └Ц─┌ФЁ╗Ф└▐О╪▄Х©≥И┤▄Г └ $0.69$ Ф≤╞Е°╗Д╨▄Е┬├Г╠╩Ф╗║Е·▀Х╝╜Г╩┐Х©┤Г╗▀Д╦╜Г╩▐Е╦╦Д╪ Г╒╟Е┬╟Г └Д╦─Д╦╙ Loss Е─╪О╪ Ф°┴Ф≈╤Е°╗Ф╗║Е·▀Х╝╜Г╩┐Е┤╨И≈╝И╒≤Ф≈╤О╪▄Ф≈═Х╝╨Ф┬▒Д╩╛Е╕┌Д╫∙Х©⌡Х║▄Х©╜Д╩ёО╪▄Ф╗║Е·▀Г └ Loss Е─╪Е╖▀Г╩┬Ф│▓Е╝ Е°╗ $0.69$О╪⌡Ф┬√Х─┘Е°╗Ф╗║Е·▀Е┬ Е┬²Е╖▀Е▄√Е╝▄Ф┬░Г╛╛Д╦─Ф╛║Х©╜Д╩ёЕ░▌О╪▄Е┘╤ Loss Е─╪Д╧÷Е╬┬Е▐╞Х┐╫Ф≤╞ $0.69$О╪▄Х©≥Х║╗Ф≤▌Ф┬▒Д╩╛Г └Ф╗║Е·▀Е╫⌠Е┴█Ф≤╞Д╦█Е┘╥Е╓┤Д╩╩Д╫∙Е┬╓Е┬╚Х┐╫Е┼⌡Г └О╪▄Е⌡═Д╦╨Е┘╤Е╞╧Д╨▌Д╦╓Д╦╙Г╠╩Е┬╚Д╦╜Г └Д╩╩Д╫∙Д╦─Д╦╙И┐╫Х╝╓Д╦╨Ф╕┌Г▌┤Ф≤╞ $0.5$Ц─┌</p>

<p>Д╦▀И²╒Ф┬▒Д╩╛Ф²╔Г°▀Д╦─Д╦▀Г⌡╦Е╞╧Г├╣Г └Ф╕┌Е©╣О╪ </p>

<ul>
  <li>
    <p><strong>Г⌡╦Е╞╧Г├╣ (Relative Entropy)</strong>О╪ Е▐┬Г╖╟ <strong>KL Ф∙ёЕ╨╕ (Kullback-Leibler Divergence, KLD)</strong>О╪▄Г■╗Д╨▌Х║║И┤▐Д╦╓Д╦╙Ф╕┌Г▌┤Е┬├Е╦┐Д╧▀И≈╢Г └Е╥╝Е╪┌ (Ф┬√Х─┘Х╞╢Х╥²Г╕╩)Ц─┌ФЁ╗Ф└▐О╪▄Х≥╫Г└╤ KL Ф∙ёЕ╨╕Е▐╞Д╩╔Х║║И┤▐Д╦╓Д╦╙Е┬├Е╦┐Д╧▀И≈╢Г └Х╥²Г╕╩О╪▄Д╫├Е╝┐Ф°╛Х╨╚Е╧╤Д╦█Ф≤╞Д╦─Д╦╙Х╥²Г╕╩Е┤╫Ф∙╟О╪▄Е⌡═Д╦╨Х╥²Г╕╩Е┤╫Ф∙╟Е┘╥Ф°┴Е╞╧Г╖╟Ф─╖О╪▄Е█Ё $P$ Е┬╟ $Q$ Г └Х╥²Г╕╩Е©┘И║╩Г╜┴Д╨▌ $Q$ Е┬╟ $P$ Г └Х╥²Г╕╩О╪▄Х─▄Г⌡╦Е╞╧Г├╣Д╦█Е┘╥Е╓┤Х©≥Г╖█Е╞╧Г╖╟Ф─╖Ц─┌</p>

\[D_{\mathrm{KL}}(P, Q) = \mathrm{E}_{X \sim P}\left[\log \dfrac{P(X)}{Q(X)}\right]\]

    <p>Е┘╤Д╦╜О╪▄$P$ Ф≤╞Ф∙╟Ф█╝Г └Г°÷Е╝·Е┬├Е╦┐О╪▄$Q$ Ф≤╞Ф╗║Е·▀Ф▀÷Е░┬Г └Е┬├Е╦┐О╪▄Д╨▄Х─┘Е╝ Д╧┴Е°╗Г⌡╦Е░▄Г └Ф╕┌Г▌┤Г╘╨И≈╢Д╦┼Ц─┌Ф┬▒Д╩╛И°─Х╕│Г■╗Ф▀÷Е░┬Е┬├Е╦┐ $Q$ Е▌╩И─╪Х©▒Г°÷Е╝·Е┬├Е╦┐ $P$О╪▄Ф┴─Д╩╔Г⌡╦Е╞╧Г├╣Д╦█Е┘╥Е╓┤Е╞╧Г╖╟Ф─╖Ц─┌</p>
  </li>
</ul>

<p>Д╦▀И²╒Ф┬▒Д╩╛Е├█Ф²╔Г°▀Д╦─Д╦▀Д╨╓Е▐┴Г├╣Г └Е┘╛Е╪▐О╪ </p>

<ul>
  <li>
    <p><strong>Д╨╓Е▐┴Г├╣ (Cross Entropy)</strong>О╪ Г■╗Д╨▌Х║║И┤▐Д╦╓Д╦╙Е┬├Е╦┐Д╧▀И≈╢Г └Г⌡╦Д╪╪Е╨╕Ц─┌</p>

\[H(P,Q)= -\sum_{i=1}^{n}P(x_i)\log Q(x_i)\]
  </li>
</ul>

<p>Д╦▀И²╒Ф┬▒Д╩╛Е╞╧Г⌡╦Е╞╧Г├╣Г └Е┘╛Е╪▐Х©⌡Х║▄Е╠∙Е╪─Ф▌╗Е╞╪Е▐≤Ф█╒О╪▄Ф²╔Х╖┌Е╞÷Д╦─Д╦▀Г⌡╦Е╞╧Г├╣Д╦▌Д©║Ф│╞Г├╣Е▓▄Д╨╓Е▐┴Г├╣Д╧▀И≈╢Г └Е┘ЁГЁ╩О╪ </p>

\[\begin{aligned}
D_{\mathrm{KL}}(P, Q) &amp;= \mathrm{E}_{X \sim P}\left[\log \dfrac{P(X)}{Q(X)}\right] \\[2ex]
&amp;= \mathrm{E}_{X \sim P} [\log P(X) - \log Q(X) ] \\[2ex]
&amp;= \sum_{i=1}^{n} P(x_i) [\log P(x_i) - \log Q(x_i) ] \\[2ex]
&amp;= \sum_{i=1}^{n} P(x_i) \log P(x_i) - \sum_{i=1}^{n} P(x_i) \log Q(x_i) \\[2ex]
&amp;= H(P, Q) - H(P)
\end{aligned}\]

<p>Ф┴─Д╩╔О╪▄<strong>Д╨╓Е▐┴Г├╣Г╜┴Д╨▌Д©║Ф│╞Г├╣Е┼═Д╦┼Г⌡╦Е╞╧Г├╣</strong>О╪ </p>

\[H(P, Q) = H(P) + D_{\mathrm{KL}}(P, Q)\]

<p>Х©≥И┤▄О╪▄$P$ Д╦╨Х╝╜Г╩┐И⌡├Д╦╜Г └Ф═╥Ф°╛Е┬├Е╦┐О╪▄$Q$ Д╦╨Ф╗║Е·▀Г╩≥Е┤╨Г └Е┬├Е╦┐Ц─┌Ф┴─Д╩╔Е°╗Ф°╨Е≥╗Е╜╕Д╧═Д╦╜О╪▄Ф┬▒Д╩╛Ф°─Е╟▐Е▄√Д╨╓Е▐┴Г├╣Е╝·И≥┘Д╦┼Г╜┴Д╩╥Д╨▌Ф°─Е╟▐Е▄√Г⌡╦Е╞╧Г├╣О╪▄Е⌡═Д╦╨Х╝╜Г╩┐И⌡├Ф≤╞Е⌡╨Е╝ Г └О╪▄Ф┴─Д╩╔ $H(P)$ Е°╗Х©≥И┤▄Ф≤╞Д╦─Д╦╙Е╦╦Ф∙╟Ц─┌</p>

<h4 id="nncrossentropyloss"><code class="language-plaintext highlighter-rouge">nn.CrossEntropyLoss</code></h4>

<p><strong>Е┼÷Х┐╫</strong>О╪ <code class="language-plaintext highlighter-rouge">nn.LogSoftmax()</code> Д╦▌ <code class="language-plaintext highlighter-rouge">nn.NLLLoss()</code> Г╩⌠Е░┬О╪▄Х©⌡Х║▄Д╨╓Е▐┴Г├╣Х╝║Г╝≈Ц─┌</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span>
    <span class="n">weight</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">size_average</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">ignore_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span>
    <span class="nb">reduce</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">reduction</span><span class="o">=</span><span class="s">'mean'</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>Д╦╩Х╕│Е▐┌Ф∙╟</strong>О╪ </p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">weight</code>О╪ Е░└Г╠╩Е┬╚Г └ loss Х╝╬Г╫╝Ф²┐Е─╪Ц─┌</li>
  <li><code class="language-plaintext highlighter-rouge">ignore_index</code>О╪ Е©╫Г∙╔Ф÷░Д╦╙Г╠╩Е┬╚О╪▄Д╦█Х╝║Г╝≈Е┘╤ lossЦ─┌</li>
  <li><code class="language-plaintext highlighter-rouge">reduction</code>О╪ Х╝║Г╝≈Ф╗║Е╪▐О╪▄Е▐╞Д╦╨ <code class="language-plaintext highlighter-rouge">none/sum/mean</code>Ц─┌
    <ul>
      <li><code class="language-plaintext highlighter-rouge">none</code>О╪ И─░Д╦╙Е┘┐Г╢═Х╝║Г╝≈Ц─┌</li>
      <li><code class="language-plaintext highlighter-rouge">sum</code>О╪ Ф┴─Ф°┴Е┘┐Г╢═Ф╠┌Е▓▄О╪▄Х©■Е⌡·Ф═┤И┤▐Ц─┌</li>
      <li><code class="language-plaintext highlighter-rouge">mean</code>О╪ Е┼═Ф²┐Е╧ЁЕ²┤О╪▄Х©■Е⌡·Ф═┤И┤▐Ц─┌</li>
    </ul>
  </li>
</ul>

<p><strong>PyTorch Д╦╜ <code class="language-plaintext highlighter-rouge">nn.CrossEntropyLoss</code> Г └Д╨╓Е▐┴Г├╣Х╝║Г╝≈Е┘╛Е╪▐</strong>О╪ </p>

<ul>
  <li>
    <p>Ф╡║Ф°┴И▓┬Е╞╧Е░└Г╠╩Е┬╚ loss Х╝╬Г╫╝Ф²┐Е─╪Г └Ф┐┘Е├╣О╪ </p>

\[\mathrm{loss}(x, class) = -\log \left(\dfrac{\exp(x[class])}{\sum_j \exp(x[j])} \right) = -x[class] + \log \left(\sum_j \exp(x[j])\right)\]
  </li>
  <li>
    <p>Е╞╧Е░└Г╠╩Е┬╚ loss Х╝╬Г╫╝Ф²┐Е─╪Г └Ф┐┘Е├╣О╪ </p>

\[\mathrm{loss}(x, class) = \mathrm{weight}[class] \left(-x[class] + \log \left(\sum_j \exp(x[j])\right)\right)\]
  </li>
</ul>

<p>ФЁ╗Ф└▐О╪▄Х©≥И┤▄Г └Х╝║Г╝≈Х©┤Г╗▀Е▓▄Д╨╓Е▐┴Г├╣Е┘╛Е╪▐Е╜≤Е°╗Д╦─Д╨⌡Е╥╝Е╪┌О╪ </p>

\[H(P,Q)= -\sum_{i=1}^{n}P(x_i)\log Q(x_i)\]

<p>Е⌡═Д╦╨Х©≥И┤▄Ф┬▒Д╩╛Е╥╡Г╩▐Е╟├Д╦─Д╦╙Е┘╥Д╫⌠Ф∙╟Ф█╝Г┌╧Е▐√Е┤╨О╪▄Ф┴─Д╩╔Х©≥И┤▄ $\Sigma$ Ф╠┌Е▓▄Е╪▐Д╦█Е├█И°─Х╕│О╪▄Е╧╤Д╦■ $P(x_i)=1$О╪▄Е⌡═Ф╜╓Е┘╛Е╪▐Е▐≤Д╦╨О╪ </p>

\[H(P,Q)= -\log Q(x_i)\]

<p>Г└╤Е░▌О╪▄Д╦╨Д╨├Д╫©Х╬⌠Е┤╨Ф╕┌Г▌┤Е°╗ $[0,1]$ Д╧▀И≈╢О╪▄PyTorch Е°╗Х©≥И┤▄Д╫©Г■╗Д╨├Д╦─Д╦╙ Softmax Е┤╫Ф∙╟Е╞╧Ф∙╟Ф█╝Х©⌡Х║▄Д╨├Е╫▓Д╦─Е▄√Е╓└Г░├О╪▄Д╫©Е┘╤Х░╫Е°╗Д╦─Д╦╙Ф╜ёЕ╦╦Г └Ф╕┌Г▌┤Е─╪Х▄┐Е⌡╢Е├┘Ц─┌</p>

<p><strong>Д╩ёГ═│Г╓╨Д╬▀</strong>О╪ </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># fake data
</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>  <span class="c1"># ФЁ╗Ф└▐ label Е°╗Х©≥И┤▄Е©┘И║╩Х╝╬Г╫╝Д╦╨И∙©Ф∙╢Е·▀
</span>
<span class="c1"># ------------------------ CrossEntropy loss: reduction ----------------------
# def loss function
</span><span class="n">loss_f_none</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'none'</span><span class="p">)</span>
<span class="n">loss_f_sum</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'sum'</span><span class="p">)</span>
<span class="n">loss_f_mean</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'mean'</span><span class="p">)</span>

<span class="c1"># forward
</span><span class="n">loss_none</span> <span class="o">=</span> <span class="n">loss_f_none</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">loss_sum</span> <span class="o">=</span> <span class="n">loss_f_sum</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">loss_mean</span> <span class="o">=</span> <span class="n">loss_f_mean</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="c1"># view
</span><span class="k">print</span><span class="p">(</span><span class="s">"Cross Entropy Loss:</span><span class="se">\n</span><span class="s"> "</span><span class="p">,</span> <span class="n">loss_none</span><span class="p">,</span> <span class="n">loss_sum</span><span class="p">,</span> <span class="n">loss_mean</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Х╬⌠Е┤╨Г╩⌠Ф·°О╪ </p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre>Cross Entropy Loss:
  tensor([1.3133, 0.1269, 0.1269]) tensor(1.5671) tensor(0.5224)
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Е▐╞Д╩╔Г°▀Е┬╟О╪▄<code class="language-plaintext highlighter-rouge">reduction</code> Е▐┌Ф∙╟И║╧Е°╗ <code class="language-plaintext highlighter-rouge">none</code> Ф╗║Е╪▐Д╦▀О╪▄Х╝║Г╝≈Е┤╨Г └ 3 Д╦╙Ф═╥Ф°╛Г └ loss Е─╪Е┬├Е┬╚Д╦╨ $1.3133$Ц─│$0.1269$ Е▓▄ $0.1269$О╪⌡Е°╗ <code class="language-plaintext highlighter-rouge">sum</code> Ф╗║Е╪▐Д╦▀О╪▄Х╝║Г╝≈Е┤╨ 3 Д╦╙Ф═╥Ф°╛Г └ loss Д╧▀Е▓▄Д╦╨ $1.5671$О╪⌡Е°╗ <code class="language-plaintext highlighter-rouge">mean</code> Ф╗║Е╪▐Д╦▀О╪▄Х╝║Г╝≈Е┤╨ 3 Д╦╙Ф═╥Ф°╛Г └ loss Е╧ЁЕ²┤Д╦╨ $0.5224$Ц─┌</p>

<p>Д╦▀И²╒Ф┬▒Д╩╛Д╩╔Г╛╛Д╦─Д╦╙Ф═╥Ф°╛Г └ loss Е─╪Д╦╨Д╬▀О╪▄И─ Х©┤Ф┴▀Е┼╗Х╝║Г╝≈Ф²╔И╙▄Х╞│Д╦─Д╦▀Ф┬▒Д╩╛Е┴█И²╒Ф▌╗Е╞╪Е┤╨Г └Е┘╛Е╪▐Г └Ф╜ёГ║╝Ф─╖О╪ </p>

\[\mathrm{loss}(x, class) = -x[class] + \log \left(\sum_j \exp(x[j])\right)\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td class="rouge-code"><pre><span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">input_1</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">detach</span><span class="p">().</span><span class="n">numpy</span><span class="p">()[</span><span class="n">idx</span><span class="p">]</span>      <span class="c1"># [1, 2]
</span><span class="n">target_1</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="n">numpy</span><span class="p">()[</span><span class="n">idx</span><span class="p">]</span>              <span class="c1"># [0]
</span>
<span class="c1"># Г╛╛Д╦─И║╧
</span><span class="n">x_class</span> <span class="o">=</span> <span class="n">input_1</span><span class="p">[</span><span class="n">target_1</span><span class="p">]</span>

<span class="c1"># Г╛╛Д╨▄И║╧
</span><span class="n">sigma_exp_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">,</span> <span class="n">input_1</span><span class="p">)))</span>
<span class="n">log_sigma_exp_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">sigma_exp_x</span><span class="p">)</span>

<span class="c1"># Х╬⌠Е┤╨loss
</span><span class="n">loss_1</span> <span class="o">=</span> <span class="o">-</span><span class="n">x_class</span> <span class="o">+</span> <span class="n">log_sigma_exp_x</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Г╛╛Д╦─Д╦╙Ф═╥Ф°╛Г └ loss Д╦╨: "</span><span class="p">,</span> <span class="n">loss_1</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Х╬⌠Е┤╨Г╩⌠Ф·°О╪ </p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>Г╛╛Д╦─Д╦╙Ф═╥Ф°╛Г └ loss Д╦╨:  1.3132617
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Д╦▀И²╒Ф┬▒Д╩╛Ф²╔Г°▀Д╦─Д╦▀И▓┬Е╞╧Е░└Г╠╩Е┬╚ loss Х╝╬Г╫╝Ф²┐Е─╪Г └Ф┐┘Е├╣О╪ </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td class="rouge-code"><pre><span class="c1"># def loss function
# Е░▒И┤▐И∙©Е╨╕Е╨■Х╞╔Д╦▌Г╠╩Е┬╚Ф∙╟И┤▐Д╦─Х┤╢О╪▄Е╕┌Ф·° reduction Е▐┌Ф∙╟Д╦╨ 'mean'О╪▄И┌ёД╧┬Ф┬▒Д╩╛Д╦█И°─Х╕│Е┘ЁФЁ╗
# weight Г └Е╟╨Е╨╕О╪▄Е▐╙И°─Х╕│Е┘ЁФЁ╗Е░└Г╠╩Е┬╚Г └ weight Ф╞■Д╬▀Е█ЁЕ▐╞Ц─┌
</span><span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)</span>
<span class="c1"># weights = torch.tensor([0.7, 0.3], dtype=torch.float)
</span>
<span class="n">loss_f_none_w</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'none'</span><span class="p">)</span>
<span class="n">loss_f_sum</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'sum'</span><span class="p">)</span>
<span class="n">loss_f_mean</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'mean'</span><span class="p">)</span>

<span class="c1"># forward
</span><span class="n">loss_none_w</span> <span class="o">=</span> <span class="n">loss_f_none_w</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">loss_sum</span> <span class="o">=</span> <span class="n">loss_f_sum</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">loss_mean</span> <span class="o">=</span> <span class="n">loss_f_mean</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="c1"># view
</span><span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">weights: "</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">loss_none_w</span><span class="p">,</span> <span class="n">loss_sum</span><span class="p">,</span> <span class="n">loss_mean</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Х╬⌠Е┤╨Г╩⌠Ф·°О╪ </p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre>weights:  tensor([1., 2.])
tensor([1.3133, 0.2539, 0.2539]) tensor(1.8210) tensor(0.3642)
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Е╞╧Ф╞■Д╧▀Е┴█Ф╡║Ф°┴Х╝╬Г╫╝Ф²┐Е─╪Г └Г╩⌠Ф·°О╪▄Ф┬▒Д╩╛Е▐▒Г▌╟О╪▄Е°╗ <code class="language-plaintext highlighter-rouge">none</code> Ф╗║Е╪▐Д╦▀О╪▄Г■╠Д╨▌Г╛╛Д╦─Д╦╙Ф═╥Ф°╛Г╠╩Е┬╚Д╦╨ 0О╪▄Х─▄Е┘╤Ф²┐Е─╪Д╦╨ $1$О╪▄Ф┴─Д╩╔Г╩⌠Ф·°Е▓▄Д╧▀Е┴█Д╦─Ф═╥О╪▄И┐╫Ф≤╞ $1.3133$Ц─┌Х─▄Г╛╛Д╨▄Д╦╙Е▓▄Г╛╛Д╦┴Д╦╙Ф═╥Ф°╛Г╠╩Е┬╚Д╦╨ $1$О╪▄Ф²┐Е─╪Д╦╨ $2$О╪▄Ф┴─Д╩╔Х©≥И┤▄Г └ loss Ф≤╞Д╧▀Е┴█Г └ $2$ Е─█О╪▄Е█Ё $0.2539$Ц─┌Е╞╧Д╨▌ <code class="language-plaintext highlighter-rouge">sum</code> Ф╗║Е╪▐О╪▄Е┘╤Г╩⌠Ф·°Д╦╨Д╦┴Д╦╙Ф═╥Ф°╛Г └ loss Д╧▀Е▓▄О╪▄Е█Ё $1.8210$Ц─┌Х─▄Е╞╧Д╨▌ <code class="language-plaintext highlighter-rouge">mean</code> Ф╗║Е╪▐О╪▄Г▌╟Е°╗Д╦█Е├█Ф≤╞Г╝─Е█∙Е°╟Е╟├Д╦┴Д╦╙ loss Г⌡╦Е┼═Ф╠┌Е╧ЁЕ²┤О╪▄Х─▄Ф≤╞И┤┤Г■╗Д╨├Е┼═Ф²┐Е╧ЁЕ²┤Г └Х╝║Г╝≈Ф√╧Е╪▐О╪ Е⌡═Д╦╨Г╛╛Д╦─Д╦╙Ф═╥Ф°╛Ф²┐Е─╪Д╦╨ $1$О╪▄Г╛╛Д╨▄Д╦╙Е▓▄Г╛╛Д╦┴Д╦╙Ф═╥Ф°╛Ф²┐Е─╪И┐╫Ф≤╞ $2$О╪▄Ф┴─Д╩╔Д╦─Е┘╠Ф°┴ $1+2+2=5$ Д╩╫О╪▄loss Г └Е┼═Ф²┐Е²┤Е─╪Д╦╨ $1.8210 / 5 = 0.3642$Ц─┌</p>

<p>Д╦▀И²╒Ф┬▒Д╩╛И─ Х©┤Ф┴▀Е┼╗Х╝║Г╝≈Ф²╔И╙▄Х╞│Е°╗Х╝╬Г╫╝Ф²┐Е─╪Г └Ф┐┘Е├╣Д╦▀О╪▄<code class="language-plaintext highlighter-rouge">mean</code> Ф╗║Е╪▐Д╦▀Г └ loss Х╝║Г╝≈Ф√╧Е╪▐Ф≤╞Е░╕Ф╜ёГ║╝О╪ </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre><span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)</span>
<span class="n">weights_all</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">weights</span><span class="p">.</span><span class="n">numpy</span><span class="p">()[</span><span class="n">x</span><span class="p">],</span> <span class="n">target</span><span class="p">.</span><span class="n">numpy</span><span class="p">())))</span>

<span class="n">mean</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">loss_sep</span> <span class="o">=</span> <span class="n">loss_none</span><span class="p">.</span><span class="n">detach</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">target</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">x_class</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="n">numpy</span><span class="p">()[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">loss_sep</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">weights</span><span class="p">.</span><span class="n">numpy</span><span class="p">()[</span><span class="n">x_class</span><span class="p">]</span> <span class="o">/</span> <span class="n">weights_all</span><span class="p">)</span>
    <span class="n">mean</span> <span class="o">+=</span> <span class="n">tmp</span>

<span class="k">print</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Х╬⌠Е┤╨Г╩⌠Ф·°О╪ </p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>0.3641947731375694
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Е▐╞Д╩╔Г°▀Е┬╟О╪▄Ф┴▀Е┼╗Х╝║Г╝≈Г └Г╩⌠Ф·°Е▓▄ PyTorch Д╦╜Х┤╙Е┼╗Ф╠┌Е▐√Г └Г╩⌠Ф·°Д╦─Х┤╢О╪▄Ф┴─Д╩╔Е╞╧Д╨▌Х╝╬Г╫╝Ф²┐Е─╪Г └Ф┐┘Е├╣О╪▄<code class="language-plaintext highlighter-rouge">mean</code> Ф╗║Е╪▐Д╦▀Г └ loss Д╦█Ф≤╞Г╝─Е█∙Г └Ф╠┌Е▓▄Д╧▀Е░▌И≥╓Д╩╔Ф═╥Ф°╛Д╦╙Ф∙╟О╪▄Х─▄Ф≤╞И≥╓Д╩╔Ф²┐Е─╪Г └Д╩╫Ф∙╟О╪▄Е█ЁЕ╝·И≥┘Х╝║Г╝≈Г └Ф≤╞Е┼═Ф²┐Е²┤Е─╪Ц─┌</p>

<h2 id="3-nllbcebcewithlogits-loss">3. NLL/BCE/BCEWithLogits Loss</h2>

<h4 id="nnnllloss"><code class="language-plaintext highlighter-rouge">nn.NLLLoss</code></h4>

<p><strong>Е┼÷Х┐╫</strong>О╪ Е╝·Г▌╟Х╢÷Е╞╧Ф∙╟Д╪╪Г└╤Е┤╫Ф∙╟Д╦╜Г └ <strong>Х╢÷Е▐╥Е┼÷Х┐╫</strong>Ц─┌</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="n">nn</span><span class="p">.</span><span class="n">NLLLoss</span><span class="p">(</span>
    <span class="n">weight</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">size_average</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">ignore_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span>
    <span class="nb">reduce</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">reduction</span><span class="o">=</span><span class="s">'mean'</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>Д╦╩Х╕│Е▐┌Ф∙╟</strong>О╪ </p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">weight</code>О╪ Е░└Г╠╩Е┬╚Г └ loss Х╝╬Г╫╝Ф²┐Е─╪Ц─┌</li>
  <li><code class="language-plaintext highlighter-rouge">ignore_index</code>О╪ Е©╫Г∙╔Ф÷░Д╦╙Г╠╩Е┬╚Ц─┌</li>
  <li><code class="language-plaintext highlighter-rouge">reduction</code>О╪ Х╝║Г╝≈Ф╗║Е╪▐О╪▄Е▐╞Д╦╨ <code class="language-plaintext highlighter-rouge">none/sum/mean</code>Ц─┌
    <ul>
      <li><code class="language-plaintext highlighter-rouge">none</code>О╪ И─░Д╦╙Е┘┐Г╢═Х╝║Г╝≈Ц─┌</li>
      <li><code class="language-plaintext highlighter-rouge">sum</code>О╪ Ф┴─Ф°┴Е┘┐Г╢═Ф╠┌Е▓▄О╪▄Х©■Е⌡·Ф═┤И┤▐Ц─┌</li>
      <li><code class="language-plaintext highlighter-rouge">mean</code>О╪ Е┼═Ф²┐Е╧ЁЕ²┤О╪▄Х©■Е⌡·Ф═┤И┤▐Ц─┌</li>
    </ul>
  </li>
</ul>

<p><strong>Х╝║Г╝≈Е┘╛Е╪▐</strong>О╪ </p>

\[\ell(x,y) = L = \{l_1,\dots,l_N\}^{\mathrm T}\;,\qquad l_n = -w_{y_n}x_{n,y_n}\]

<p><strong>Д╩ёГ═│Г╓╨Д╬▀</strong>О╪ </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td class="rouge-code"><pre><span class="c1"># fake data, Х©≥И┤▄Ф┬▒Д╩╛Д╫©Г■╗Г └Х©≤Ф≤╞Д╧▀Е┴█Г └Ф∙╟Ф█╝О╪▄ФЁ╗Ф└▐ label Е°╗Х©≥И┤▄Е©┘И║╩Х╝╬Г╫╝Д╦╨ long
</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>

<span class="c1"># weights
</span><span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)</span>

<span class="c1"># NLL loss
</span><span class="n">loss_f_none_w</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">NLLLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'none'</span><span class="p">)</span>
<span class="n">loss_f_sum</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">NLLLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'sum'</span><span class="p">)</span>
<span class="n">loss_f_mean</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">NLLLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'mean'</span><span class="p">)</span>

<span class="c1"># forward
</span><span class="n">loss_none_w</span> <span class="o">=</span> <span class="n">loss_f_none_w</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">loss_sum</span> <span class="o">=</span> <span class="n">loss_f_sum</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">loss_mean</span> <span class="o">=</span> <span class="n">loss_f_mean</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="c1"># view
</span><span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">weights: "</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"NLL Loss"</span><span class="p">,</span> <span class="n">loss_none_w</span><span class="p">,</span> <span class="n">loss_sum</span><span class="p">,</span> <span class="n">loss_mean</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Х╬⌠Е┤╨Г╩⌠Ф·°О╪ </p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre>weights:  tensor([1., 1.])
NLL Loss tensor([-1., -3., -3.]) tensor(-7.) tensor(-2.3333)
</pre></td></tr></tbody></table></code></pre></div></div>

<p>ФЁ╗Ф└▐О╪▄Х©≥И┤▄ <code class="language-plaintext highlighter-rouge">nn.NLLLoss</code> Е╝·И≥┘Д╦┼Е▐╙Ф≤╞Е╝·Г▌╟Д╨├Д╦─Д╦╙Х╢÷Е▐╥Г └Е┼÷Х┐╫Ц─┌Е╞╧Д╨▌ <code class="language-plaintext highlighter-rouge">none</code> Ф╗║Е╪▐О╪ Х©≥И┤▄Г╛╛Д╦─Д╦╙Ф═╥Ф°╛Ф≤╞Г╛╛ 0 Г╠╩О╪▄Ф┴─Д╩╔Ф┬▒Д╩╛Х©≥И┤▄Е▐╙Е╞╧Г╛╛Д╦─Д╦╙Г╔·Г╩▐Е┘┐Х©⌡Х║▄Х╝║Г╝≈О╪▄Е▐√Х╢÷Е▐╥Е╬≈Е┬╟ NLL Loss Д╦╨ $-1$О╪⌡Г╛╛Д╨▄Д╦╙Ф═╥Ф°╛Ф≤╞Г╛╛ 1 Г╠╩О╪▄Ф┬▒Д╩╛Е╞╧Г╛╛Д╨▄Д╦╙Г╔·Г╩▐Е┘┐Х©⌡Х║▄Х╝║Г╝≈О╪▄Е▐√Х╢÷Е▐╥Е╬≈Е┬╟ NLL Loss Д╦╨ $-3$О╪⌡Г╛╛Д╦┴Д╦╙Ф═╥Ф°╛Д╧÷Ф≤╞Г╛╛ 1 Г╠╩О╪▄Ф┬▒Д╩╛Е╞╧Г╛╛Д╨▄Д╦╙Г╔·Г╩▐Е┘┐Х©⌡Х║▄Х╝║Г╝≈О╪▄Е▐√Х╢÷Е▐╥Е╬≈Е┬╟ NLL Loss Д╦╨ $-3$Ц─┌Е╞╧Д╨▌ <code class="language-plaintext highlighter-rouge">sum</code> Ф╗║Е╪▐О╪▄Е╟├Д╦┴Д╦╙Ф═╥Ф°╛Г └ NLL Loss Ф╠┌Е▓▄О╪▄Е╬≈Е┬╟ $-7$Ц─┌Е╞╧Д╨▌ <code class="language-plaintext highlighter-rouge">mean</code> Ф╗║Е╪▐О╪▄Е╟├Д╦┴Д╦╙Ф═╥Ф°╛Г └ NLL Loss Е┼═Ф²┐Е╧ЁЕ²┤О╪▄Е╬≈Е┬╟ $-2.3333$Ц─┌</p>

<h4 id="nnbceloss"><code class="language-plaintext highlighter-rouge">nn.BCELoss</code></h4>

<p><strong>Е┼÷Х┐╫</strong>О╪ Д╨▄Е┬├Г╠╩Д╨╓Е▐┴Г├╣Ц─┌</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="n">nn</span><span class="p">.</span><span class="n">BCELoss</span><span class="p">(</span>
    <span class="n">weight</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">size_average</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="nb">reduce</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">reduction</span><span class="o">=</span><span class="s">'mean'</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>Д╦╩Х╕│Е▐┌Ф∙╟</strong>О╪ </p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">weight</code>О╪ Е░└Г╠╩Е┬╚Г └ loss Х╝╬Г╫╝Ф²┐Е─╪Ц─┌</li>
  <li><code class="language-plaintext highlighter-rouge">ignore_index</code>О╪ Е©╫Г∙╔Ф÷░Д╦╙Г╠╩Е┬╚Ц─┌</li>
  <li><code class="language-plaintext highlighter-rouge">reduction</code>О╪ Х╝║Г╝≈Ф╗║Е╪▐О╪▄Е▐╞Д╦╨ <code class="language-plaintext highlighter-rouge">none/sum/mean</code>Ц─┌
    <ul>
      <li><code class="language-plaintext highlighter-rouge">none</code>О╪ И─░Д╦╙Е┘┐Г╢═Х╝║Г╝≈Ц─┌</li>
      <li><code class="language-plaintext highlighter-rouge">sum</code>О╪ Ф┴─Ф°┴Е┘┐Г╢═Ф╠┌Е▓▄О╪▄Х©■Е⌡·Ф═┤И┤▐Ц─┌</li>
      <li><code class="language-plaintext highlighter-rouge">mean</code>О╪ Е┼═Ф²┐Е╧ЁЕ²┤О╪▄Х©■Е⌡·Ф═┤И┤▐Ц─┌</li>
    </ul>
  </li>
</ul>

<p><strong>Х╝║Г╝≈Е┘╛Е╪▐</strong>О╪ </p>

\[l_n = -w_n [y_n \cdot \log x_n + (1- y_n) \cdot \log(1-x_n)]\]

<p><strong>ФЁ╗Ф└▐Д╨▀И║╧</strong>О╪ Г■╠Д╨▌Д╨╓Е▐┴Г├╣Ф≤╞Х║║И┤▐Д╦╓Д╦╙Ф╕┌Г▌┤Е┬├Е╦┐Д╧▀И≈╢Г └Е╥╝Е╪┌О╪▄Е⌡═Ф╜╓Х╬⌠Е┘╔Е─╪Е▐√Е─╪Е©┘И║╩Е°╗ $[0, 1]$Ц─┌</p>

<p><strong>Д╩ёГ═│Г╓╨Д╬▀</strong>О╪ </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td class="rouge-code"><pre><span class="c1"># fake data, Х©≥И┤▄Ф┬▒Д╩╛Х╝╬Г╫╝ 4 Д╦╙Ф═╥Ф°╛О╪▄ФЁ╗Ф└▐ label Е°╗Х©≥И┤▄Е©┘И║╩Х╝╬Г╫╝Д╦╨ float
</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)</span>

<span class="n">target_bce</span> <span class="o">=</span> <span class="n">target</span>

<span class="c1"># itarget
</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>  <span class="c1"># Е┬╘Г■╗ Sigmoid Е┤╫Ф∙╟Е╟├Х╬⌠Е┘╔Е─╪Е▌▀Г╪╘Е┬╟ [0,1]
</span>
<span class="c1"># weights
</span><span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">)</span>

<span class="c1"># BCE loss
</span><span class="n">loss_f_none_w</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BCELoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'none'</span><span class="p">)</span>
<span class="n">loss_f_sum</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BCELoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'sum'</span><span class="p">)</span>
<span class="n">loss_f_mean</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BCELoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'mean'</span><span class="p">)</span>

<span class="c1"># forward
</span><span class="n">loss_none_w</span> <span class="o">=</span> <span class="n">loss_f_none_w</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target_bce</span><span class="p">)</span>
<span class="n">loss_sum</span> <span class="o">=</span> <span class="n">loss_f_sum</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target_bce</span><span class="p">)</span>
<span class="n">loss_mean</span> <span class="o">=</span> <span class="n">loss_f_mean</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target_bce</span><span class="p">)</span>

<span class="c1"># view
</span><span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">weights: "</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"BCE Loss"</span><span class="p">,</span> <span class="n">loss_none_w</span><span class="p">,</span> <span class="n">loss_sum</span><span class="p">,</span> <span class="n">loss_mean</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Х╬⌠Е┤╨Г╩⌠Ф·°О╪ </p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre>weights:  tensor([1., 1.])
BCE Loss tensor([[0.3133, 2.1269],
        [0.1269, 2.1269],
        [3.0486, 0.0181],
        [4.0181, 0.0067]]) tensor(11.7856) tensor(1.4732)
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Г■╠Д╨▌Х©≥И┤▄Ф┬▒Д╩╛Ф°┴ 4 Д╦╙Ф═╥Ф°╛О╪▄Ф╞▐Д╦╙Ф═╥Ф°╛Ф°┴ 2 Д╦╙Г╔·Г╩▐Е┘┐О╪▄Е⌡═Ф╜╓Е°╗ <code class="language-plaintext highlighter-rouge">none</code> Ф╗║Е╪▐Д╦▀Ф┬▒Д╩╛Х©≥И┤▄Е╬≈Е┬╟ 8 Д╦╙ lossО╪▄Е█ЁФ╞▐Д╦─Д╦╙Г╔·Г╩▐Е┘┐Д╪ Д╦─Д╦─Е╞╧Е╨■Е°╟Х╝║Г╝≈ lossЦ─┌Х─▄ <code class="language-plaintext highlighter-rouge">sum</code> Ф╗║Е╪▐Е╟╠Ф≤╞Г╝─Е█∙Е°╟Е╟├Х©≥ 8 Д╦╙ loss Х©⌡Х║▄Г⌡╦Е┼═О╪▄<code class="language-plaintext highlighter-rouge">mean</code> Ф╗║Е╪▐Е╟╠Ф≤╞Е╞╧Х©≥ 8 Д╦╙ loss Ф╠┌Е┼═Ф²┐Е²┤Е─╪Ц─┌</p>

<p>Д╦▀И²╒Ф┬▒Д╩╛И─ Х©┤Ф┴▀Е┼╗Х╝║Г╝≈Ф²╔И╙▄Х╞│Г╛╛Д╦─Д╦╙Г╔·Г╩▐Е┘┐Г └ BCE loss Е─╪Ф≤╞Е░╕Г╜┴Д╨▌ $0.3133$О╪ </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre><span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">x_i</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">detach</span><span class="p">().</span><span class="n">numpy</span><span class="p">()[</span><span class="n">idx</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span>  <span class="c1"># Х▌╥Е▐√Г╛╛Д╦─Д╦╙Г╔·Г╩▐Е┘┐Г └Х╬⌠Е┤╨Е─╪
</span><span class="n">y_i</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="n">numpy</span><span class="p">()[</span><span class="n">idx</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span>  <span class="c1"># Х▌╥Е▐√Г╛╛Д╦─Д╦╙Г╔·Г╩▐Е┘┐Г └Ф═┤Г╜╬
</span>
<span class="c1"># loss
# l_i = -[ y_i * np.log(x_i) + (1-y_i) * np.log(1-y_i) ]      # np.log(0) = nan
</span><span class="n">l_i</span> <span class="o">=</span> <span class="o">-</span><span class="n">y_i</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">x_i</span><span class="p">)</span> <span class="k">if</span> <span class="n">y_i</span> <span class="k">else</span> <span class="o">-</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y_i</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x_i</span><span class="p">)</span>

<span class="c1"># Х╬⌠Е┤╨loss
</span><span class="k">print</span><span class="p">(</span><span class="s">"BCE inputs: "</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Г╛╛Д╦─Д╦╙ loss Д╦╨: "</span><span class="p">,</span> <span class="n">l_i</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Х╬⌠Е┤╨Г╩⌠Ф·°О╪ </p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre>BCE inputs:  tensor([[0.7311, 0.8808],
        [0.8808, 0.8808],
        [0.9526, 0.9820],
        [0.9820, 0.9933]])
Г╛╛Д╦─Д╦╙ loss Д╦╨:  0.31326166
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Е▐╞Д╩╔Г°▀Е┬╟О╪▄Ф┴▀Е┼╗Х╝║Г╝≈Г └Г╩⌠Ф·°Д╦▌ PyTorch Д╦╜ <code class="language-plaintext highlighter-rouge">nn.BCELoss</code> Г └Х╝║Г╝≈Г╩⌠Ф·°Д╦─Х┤╢Ц─┌</p>

<h4 id="nnbcewithlogitsloss"><code class="language-plaintext highlighter-rouge">nn.BCEWithLogitsLoss</code></h4>

<p><strong>Е┼÷Х┐╫</strong>О╪ Г╩⌠Е░┬ Sigmoid Д╦▌ Д╨▄Е┬├Г╠╩Д╨╓Е▐┴Г├╣Ц─┌</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="n">nn</span><span class="p">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">(</span>
    <span class="n">weight</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">size_average</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="nb">reduce</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">reduction</span><span class="o">=</span><span class="s">'mean'</span><span class="p">,</span>
    <span class="n">pos_weight</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>Д╦╩Х╕│Е▐┌Ф∙╟</strong>О╪ </p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">pos_weight</code>О╪ Ф╜ёФ═╥Ф°╛Г └Ф²┐Е─╪Ц─┌</li>
  <li><code class="language-plaintext highlighter-rouge">weight</code>О╪ Е░└Г╠╩Е┬╚Г └ loss Х╝╬Г╫╝Ф²┐Е─╪Ц─┌</li>
  <li><code class="language-plaintext highlighter-rouge">ignore_index</code>О╪ Е©╫Г∙╔Ф÷░Д╦╙Г╠╩Е┬╚Ц─┌</li>
  <li><code class="language-plaintext highlighter-rouge">reduction</code>О╪ Х╝║Г╝≈Ф╗║Е╪▐О╪▄Е▐╞Д╦╨ <code class="language-plaintext highlighter-rouge">none/sum/mean</code>Ц─┌
    <ul>
      <li><code class="language-plaintext highlighter-rouge">none</code>О╪ И─░Д╦╙Е┘┐Г╢═Х╝║Г╝≈Ц─┌</li>
      <li><code class="language-plaintext highlighter-rouge">sum</code>О╪ Ф┴─Ф°┴Е┘┐Г╢═Ф╠┌Е▓▄О╪▄Х©■Е⌡·Ф═┤И┤▐Ц─┌</li>
      <li><code class="language-plaintext highlighter-rouge">mean</code>О╪ Е┼═Ф²┐Е╧ЁЕ²┤О╪▄Х©■Е⌡·Ф═┤И┤▐Ц─┌</li>
    </ul>
  </li>
</ul>

<p><strong>Х╝║Г╝≈Е┘╛Е╪▐</strong>О╪ </p>

\[l_n = -w_n[y_n \cdot \log \sigma(x_n) + (1-y_n)\cdot \log (1-\sigma (x_n))]\]

<hr />

<p>Д╦▀Х┼┌Е├┘Е╝╧О╪ Ф█÷Е╓╠Е┤╫Ф∙╟ (Д╦─)</p>
:ET